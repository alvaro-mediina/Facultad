# 游눹 Te칩rico de Sistemas Operativos 游

En este archivo encontrar치s un resumen o algunas ideas sobre el libro OSTEP (Operating Systems: Three Easy Pieces) y otros temas relacionados con sistemas operativos.

Como la materia se divide en 3 partes, tambi칠n dividir칠 este archivo en 3 partes, una para cada parte del libro.

Enjoy :D

# Indice
- [Introducci칩n](#introducci칩n)
   * [Introducci칩n a los Sistemas Operativos](#introducci칩n-a-los-sistemas-operativos)
   * [Virtualizando la CPU](#virtualizando-la-cpu)
   * [Virtualizando la Memoria](#virtualizando-la-memoria)
   * [Concurrencia](#concurrencia)
    * [Persistencia](#persistencia)
    * [Desiciones de dise침o](#desiciones-de-dise침o)
    * [Un poco de historia](#un-poco-de-historia)
- [Virtualizaci칩n](#virtualizacion)
    * [Dialogo](#dialogo)
    * [Procesos](#procesos)

# Introducci칩n

 Las tres piezas f치ciles se refieren a los tres elementos tem치ticos principales en los que se organiza el libro: virtualizaci칩n, concurrencia y persistencia. Al discutir estos conceptos, terminaremos hablando de la mayor칤a de las cosas importantes que hace un sistema operativo; con suerte, tambi칠n se divertir치n en el camino.

 - El primero es el `crux` del problema. Cada vez que tratamos de resolver un problema, primero intentamos declarar cu치l es el tema m치s importante; dicho crux del problema se se침ala expl칤citamente en el texto, y esperamos que se resuelva a trav칠s de las t칠cnicas, algoritmos e ideas presentadas en el resto del texto. 
 - En muchos lugares, explicaremos c칩mo funciona un sistema mostrando su comportamiento a lo largo del tiempo. Estas l칤neas de tiempo son la esencia de la comprensi칩n; si sabes qu칠 ocurre, estar치s en camino a entender verdaderamente c칩mo opera la memoria virtual. 
 
 - Si comprendes lo que sucede cuando un sistema de archivos con journaling escribe un bloque en el disco, habr치s dado los primeros pasos hacia el dominio de los sistemas de almacenamiento.

 - Al principio de cada secci칩n principal, primero presentaremos una `abstracci칩n` que un sistema operativo proporciona, y luego trabajaremos en los cap칤tulos siguientes sobre los mecanismos, pol칤ticas y otros apoyos necesarios para proporcionar esa abstracci칩n. 
    * Las abstracciones son fundamentales en todos los aspectos de la Ciencia de la Computaci칩n, por lo que no es sorprendente que tambi칠n sean esenciales en los sistemas operativos.

> **Consejo**:  Asiste a clase, para escuchar al profesor presentar el material. Luego, al final de cada semana, lee estas notas, para ayudar a que las ideas se asienten un poco mejor en tu mente. Por supuesto, alg칰n tiempo despu칠s (pista: antes del examen), vuelve a leer las notas para consolidar tu conocimiento. Por supuesto, tu profesor sin duda asignar치 algunas tareas y proyectos, as칤 que deber칤as hacerlos; en particular, hacer proyectos donde escribas c칩digo real para resolver problemas reales es la mejor manera de poner en pr치ctica las ideas de estas notas. 

## Introducci칩n a los Sistemas Operativos

> **El CRUX del problema: C칩mo virtualizar los recursos**: El porqu칠 el sistema operativo hace esto no es la pregunta principal, ya que la respuesta deber칤a ser obvia: hace que el sistema sea m치s f치cil de usar. Por lo tanto, nos enfocamos en el c칩mo: 쯤u칠 mecanismos y pol칤ticas implementa el sistema operativo para lograr la virtualizaci칩n? 쮺칩mo lo hace de manera eficiente? 쯈u칠 soporte de hardware es necesario?

### Virtualizando la CPU

Si s칩lo tenemos un procesador 쮺칩mo ocurre la magia de correr programas al mismo tiempo? Resulta que el sistema operativo, con algo de ayuda del hardware, es el encargado de crear esta ilusi칩n, es decir, la ilusi칩n de que el sistema tiene un n칰mero muy grande de CPUs virtuales. Convertir un solo CPU (o un peque침o conjunto de ellos) en un n칰mero aparentemente infinito de CPUs y, por lo tanto, permitir que muchos programas se ejecuten aparentemente al mismo tiempo es lo que llamamos virtualizaci칩n de la CPU.

Por supuesto, para ejecutar programas, detenerlos y, en general, indicarle al sistema operativo qu칠 programas ejecutar, deben existir algunas interfaces (APIs) que puedes usar para comunicar tus deseos al sistema operativo. Hablaremos sobre estas APIs a lo largo del libro; de hecho, son la principal forma en que la mayor칤a de los usuarios interact칰a con los sistemas operativos.
    
### Virtualizando la Memoria

Ahora consideremos la memoria. El modelo de memoria f칤sica presentado por las m치quinas modernas es muy simple. La memoria es simplemente un array de bytes; para leer la memoria, se debe especificar una direcci칩n para poder acceder a los datos almacenados all칤; para escribir (o actualizar) memoria, tambi칠n se debe especificar los datos a escribir en la direcci칩n dada.

La memoria se accede todo el tiempo cuando un programa est치 en ejecuci칩n. Un programa mantiene todas sus estructuras de datos en memoria y accede a ellas mediante diversas instrucciones, como cargas y almacenamientos, o otras instrucciones expl칤citas que acceden a la memoria para realizar su trabajo. No olvides que cada instrucci칩n del programa tambi칠n est치 en memoria; por lo tanto, la memoria se accede en cada recuperaci칩n de instrucci칩n.

```C
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <sys/time.h>
#include <time.h>

void Spin(int seconds) {
    time_t start = time(NULL);
    while (time(NULL) - start < seconds) {
        // Bucle vac칤o que consume tiempo
    }
}

int main(int argc, char *argv[]){
    int *p = malloc(sizeof(int)); // a1
    assert(p != NULL);
    printf("(%d) address pointed to by p: %p\n", getpid(), p); // a2
    *p = 0; // a3
    while (1) {
        Spin(1);
        *p = *p + 1;
        printf("(%d) p: %d\n", getpid(), *p); // a4
    }
    return 0;
}
```
El programa hace un par de cosas. Primero, asigna algo de memoria (l칤nea a1). Luego, imprime la direcci칩n de la memoria (a2) y, a continuaci칩n, coloca el n칰mero cero en la primera posici칩n de la memoria reci칠n asignada (a3). Finalmente, entra en un bucle, retras치ndose durante un segundo e incrementando el valor almacenado en la direcci칩n contenida en p. Con cada declaraci칩n de impresi칩n, tambi칠n muestra lo que se llama el identificador del proceso (PID) del programa en ejecuci칩n. Este PID es 칰nico para cada proceso en ejecuci칩n. Nuevamente, este primer resultado no es muy interesante. La memoria reci칠n asignada est치 en la direcci칩n 0x200000. A medida que el programa se ejecuta, actualiza lentamente el valor y muestra el resultado.

```bash
$ gcc -o mem mem.c
[1] 15998
(15999) address pointed to by p: 0x5b34db0ce2a0
(15998) address pointed to by p: 0x578a0f4c02a0
(15999) p: 1
(15998) p: 1
(15998) p: 2
(15999) p: 2
(15999) p: 3
(15998) p: 3
(15999) p: 4
(15998) p: 4
(15999) p: 5
(15998) p: 5
(15998) p: 6
(15999) p: 6
(15999) p: 7
(15998) p: 7
(15998) p: 8
(15999) p: 8
(15999) p: 9
(15998) p: 9

```

Ahora, ejecutamos varias instancias de este mismo programa para ver qu칠 sucede (Figura 2.4). Vemos en el ejemplo que cada programa en ejecuci칩n ha asignado memoria en la misma direcci칩n (0x578a0f4c02a0), 춰y sin embargo, cada uno parece estar actualizando el valor en 0x578a0f4c02a0 de forma independiente! Es como si cada programa en ejecuci칩n tuviera su propia memoria privada, en lugar de compartir la misma memoria f칤sica con otros programas en ejecuci칩n. De hecho, eso es exactamente lo que est치 sucediendo aqu칤, ya que el sistema operativo est치 virtualizando la memoria. Cada proceso accede a su propio espacio de direcciones virtuales privado (a veces simplemente llamado su espacio de direcciones), que el sistema operativo mapea de alguna manera a la memoria f칤sica de la m치quina. Una referencia de memoria dentro de un programa en ejecuci칩n no afecta el espacio de direcciones de otros procesos (o del propio sistema operativo); en lo que respecta al programa en ejecuci칩n, tiene la memoria f칤sica solo para s칤 mismo. La realidad, sin embargo, es que la memoria f칤sica es un recurso compartido, gestionado por el sistema operativo. 

### Concurrencia

Usamos este t칠rmino conceptual para referirnos a una serie de problemas que surgen y deben ser abordados cuando se trabaja en muchas cosas al mismo tiempo (es decir, concurrentemente) en el mismo programa. Los problemas de concurrencia surgieron primero dentro del propio sistema operativo; como puedes ver en los ejemplos anteriores sobre virtualizaci칩n, el sistema operativo est치 manejando muchas cosas a la vez, ejecutando primero un proceso, luego otro, y as칤 sucesivamente. Resulta que hacer esto lleva a problemas profundos e interesantes

> El CRUX del problema:
Cuando hay muchos hilos ejecut치ndose concurrentemente dentro del mismo espacio de memoria, 쯖칩mo podemos construir un programa que funcione correctamente? 쯈u칠 primitivas se necesitan del sistema operativo? 쯈u칠 mecanismos deben proporcionar el hardware? 쮺칩mo podemos usarlos para resolver los problemas de concurrencia?

### Persistencia

El tercer tema principal del curso es la persistencia. En la memoria del sistema, los datos pueden perderse f치cilmente, ya que dispositivos como la DRAM almacenan valores de manera vol치til; cuando se corta la energ칤a o el sistema falla, cualquier dato en memoria se pierde. Por lo tanto, necesitamos hardware y software capaces de almacenar datos de manera persistente.

El software en el sistema operativo que generalmente gestiona el disco se llama el sistema de archivos; por lo tanto, es responsable de almacenar cualquier archivo que el usuario cree de manera confiable y eficiente en los discos del sistema.

A diferencia de las abstracciones proporcionadas por el sistema operativo para la CPU y la memoria, el sistema operativo no crea un disco virtualizado privado para cada aplicaci칩n. M치s bien, se asume que, a menudo, los usuarios querr치n compartir informaci칩n que est치 en archivos.

### Desiciones de dise침o

Un objetivo en el dise침o e implementaci칩n de un sistema operativo es proporcionar un alto rendimiento; otra forma de decirlo es que nuestro objetivo es minimizar los sobrecostos del OS.

Otro objetivo ser치 proporcionar protecci칩n entre aplicaciones, as칤 como entre el OS y las aplicaciones. Debido a que queremos permitir que muchos programas se ejecuten al mismo tiempo, queremos asegurarnos de que el comportamiento malicioso o accidentalmente incorrecto de uno no da침e a los dem치s; ciertamente no queremos que una aplicaci칩n pueda da침ar el propio OS (ya que eso afectar칤a a todos los programas que se ejecutan en el sistema). La protecci칩n es el coraz칩n de uno de los principales principios subyacentes de un sistema operativo, que es el de aislamiento; aislar procesos unos de otros es clave para la protecci칩n y, por lo tanto, subyace en gran parte de lo que un OS debe hacer.

### Un poco de historia

#### Primeros Sistemas Operativos: Solo Bibliotecas

En sus inicios, los sistemas operativos (OS) eran bastante rudimentarios, funcionando esencialmente como bibliotecas de funciones comunes. En lugar de que cada programador escribiera c칩digo para manejar I/O de bajo nivel, el "OS" proporcionaba APIs para facilitar el desarrollo. En estos sistemas de mainframe antiguos, solo se ejecutaba un programa a la vez, controlado por un operador humano. Mucho de lo que hoy consideramos funciones b치sicas de un OS (como decidir el orden de ejecuci칩n de trabajos) lo hac칤a este operador. Este modo de procesamiento se conoc칤a como procesamiento por lotes (batch processing), donde una serie de trabajos se configuraban y se ejecutaban en "lote" por el operador. Dado que era costoso permitir que un usuario interactuara directamente con la computadora, se utilizaba principalmente el procesamiento por lotes [BH00].

#### M치s All치 de las Bibliotecas: Protecci칩n

A medida que los sistemas operativos evolucionaron, asumieron un papel m치s central en la gesti칩n de las m치quinas. Un aspecto importante fue reconocer que el c칩digo ejecutado en nombre del OS deb칤a ser especial y tratado de manera diferente al c칩digo de aplicaci칩n normal. Permitir que cualquier aplicaci칩n leyera cualquier archivo en el disco compromet칤a la privacidad. Por lo tanto, se invent칩 la llamada a sistema (system call), un mecanismo que permiti칩 la transici칩n controlada al OS, elevando el nivel de privilegio del hardware. En contraste con una llamada a procedimiento, una llamada a sistema transfiere el control al OS mientras eleva el nivel de privilegio del hardware. Esto permiti칩 al OS tener acceso completo al hardware y realizar operaciones como solicitudes de I/O o gestionar memoria. Una vez completada la solicitud, el control se devuelve al usuario.

#### La Era del Multiprogramming
Con la llegada de las minicomputadoras, los sistemas operativos dieron un gran salto. Las m치quinas cl치sicas como la PDP de Digital Equipment hicieron que las computadoras fueran m치s asequibles, permitiendo que un grupo menor de personas dentro de una organizaci칩n tuviera su propia m치quina. Esto impuls칩 la actividad de desarrollo y la innovaci칩n en los sistemas operativos, especialmente con la multiprogramaci칩n. En lugar de ejecutar un solo trabajo a la vez, el OS cargaba m칰ltiples trabajos en memoria y cambiaba r치pidamente entre ellos para mejorar la utilizaci칩n del CPU. La necesidad de soportar multiprogramaci칩n y la superposici칩n en presencia de I/O e interrupciones llev칩 a importantes innovaciones en la protecci칩n de memoria y el manejo de la concurrencia. La introducci칩n del sistema operativo UNIX por Ken Thompson y Dennis Ritchie en Bell Labs fue un avance significativo, al simplificar y hacer m치s accesibles muchas ideas buenas de otros sistemas [O72, B+72, S68].

#### La Era Moderna
La llegada de las computadoras personales (PC) marc칩 una nueva era en la inform치tica. Las primeras PCs, como el Apple II y el IBM PC, se convirtieron en la fuerza dominante en la computaci칩n debido a su bajo costo. Sin embargo, los primeros sistemas operativos de PC, como DOS, olvidaron o nunca aprendieron las lecciones de las minicomputadoras, como la protecci칩n de memoria. Los primeros sistemas operativos de Mac (hasta la versi칩n 9) ten칤an un enfoque cooperativo para la programaci칩n, lo que permit칤a que un hilo atrapado en un bucle infinito pudiera tomar el control completo del sistema. Afortunadamente, con el tiempo, las caracter칤sticas avanzadas de los sistemas operativos de minicomputadoras comenzaron a integrarse en los sistemas de escritorio. Hoy en d칤a, sistemas como macOS, basado en UNIX, y Windows NT han adoptado muchas de las grandes ideas de la historia de la computaci칩n. Incluso los tel칠fonos m칩viles modernos, que ejecutan sistemas operativos como Linux, se asemejan m치s a los sistemas de minicomputadoras de los a침os 70 que a los PC de los a침os 80. Es gratificante ver c칩mo las buenas ideas del pasado contin칰an evolucionando y mejorando los sistemas modernos.

#### ASIDE: La importancia de UNIX

Es dif칤cil exagerar la importancia de UNIX en la historia de los sistemas operativos. Influenciado por sistemas anteriores, en particular el famoso sistema Multics del MIT, UNIX reuni칩 muchas ideas innovadoras y cre칩 un sistema tanto simple como poderoso. El principio unificador subyacente al UNIX original de "Bell Labs" era la construcci칩n de peque침os programas potentes que pod칤an conectarse entre s칤 para formar flujos de trabajo m치s grandes. El shell, donde se escriben los comandos, proporcionaba primitivas como los pipes (tuber칤as) para habilitar tal programaci칩n a nivel meta, facilitando la conexi칩n de programas para lograr una tarea m치s compleja.

Por ejemplo, para encontrar l칤neas en un archivo de texto que contengan la palabra "foo" y luego contar cu치ntas de esas l칤neas existen, se escribir칤a: grep foo file.txt | wc -l, utilizando as칤 los programas grep y wc (word count) para cumplir la tarea. El entorno UNIX era amigable tanto para programadores como para desarrolladores, proporcionando tambi칠n un compilador para el nuevo lenguaje de programaci칩n C. Facilitar que los programadores escribieran sus propios programas, as칤 como compartirlos, hizo que UNIX se volviera enormemente popular. Probablemente tambi칠n ayud칩 mucho que los autores distribuyeran copias gratuitamente a quien las solicitara, una forma temprana de software de c칩digo abierto.

Otra de las caracter칤sticas cr칤ticas fue la accesibilidad y legibilidad del c칩digo. Tener un kernel hermoso y peque침o escrito en C invitaba a otros a jugar con 칠l, agregando nuevas y geniales funcionalidades. Por ejemplo, un grupo emprendedor en Berkeley, liderado por Bill Joy, cre칩 una maravillosa distribuci칩n (la Berkeley Systems Distribution, o BSD) que inclu칤a subsistemas avanzados de memoria virtual, sistemas de archivos y redes. Joy luego cofund칩 Sun Microsystems.

Desafortunadamente, la expansi칩n de UNIX se vio un poco frenada cuando algunas empresas intentaron reclamar su propiedad y lucrar con 칠l, un resultado desafortunado (pero com칰n) cuando los abogados se involucran. Muchas empresas desarrollaron sus propias variantes: SunOS de Sun Microsystems, AIX de IBM, HPUX (conocido como "H-Pucks") de HP, e IRIX de SGI. Las disputas legales entre AT&T/Bell Labs y estos otros actores arrojaron una sombra sobre UNIX, y muchos se preguntaban si sobrevivir칤a, especialmente con la introducci칩n de Windows, que se apoder칩 de gran parte del mercado de PCs...

#### ASIDE: Y luego lleg칩 Linux

Afortunadamente para UNIX, un joven hacker finland칠s llamado Linus Torvalds decidi칩 escribir su propia versi칩n de UNIX, la cual se basaba en gran medida en los principios e ideas del sistema original, pero no en su base de c칩digo, evitando as칤 problemas legales. Torvalds cont칩 con la ayuda de muchas personas de todo el mundo y aprovech칩 las sofisticadas herramientas GNU que ya exist칤an [G85], y pronto naci칩 Linux (as칤 como el movimiento moderno de software de c칩digo abierto).

Con la llegada de la era de internet, la mayor칤a de las empresas (como Google, Amazon, Facebook y otras) optaron por usar Linux, ya que era gratuito y pod칤a modificarse f치cilmente para satisfacer sus necesidades; de hecho, es dif칤cil imaginar el 칠xito de estas nuevas compa침칤as si un sistema as칤 no hubiera existido. A medida que los tel칠fonos inteligentes se convirtieron en una plataforma dominante para los usuarios, Linux tambi칠n encontr칩 un basti칩n all칤 (a trav칠s de Android), por muchas de las mismas razones. Adem치s, Steve Jobs llev칩 consigo su entorno operativo basado en UNIX, NeXTStep, a Apple, lo que hizo que UNIX fuera popular en los escritorios (aunque muchos usuarios de la tecnolog칤a de Apple probablemente no sean conscientes de este hecho).

As칤, UNIX sigue vivo, m치s importante hoy que nunca. Los dioses de la computaci칩n, si crees en ellos, deber칤an ser agradecidos por este maravilloso resultado.

# Virtualizaci칩n

## Procesos

Definici칩n informal: Programa en ejecuci칩n

El programa en s칤 mismo es una cosa sin vida: solo est치 all칤 en el disco, un monton de instrucciones (y quiz치s 패algunos datos est치ticos), esperando entrar en acci칩n. Es el sistema  패operativo el que toma estos bytes y los pone en marcha, transformando el programa en algo util.

---
### El problema en cuesti칩n:
쮺칩mo proporcionar la ilusi칩n de muchas CPU's? A pesar de que solo hay unas pocas CPUs f칤sicas disponibles, 쮺omo puede el sistema operativo proporcionar la ilusion de un suministro casi infinito de dichas CPUs?

---

El sistema operativo crea esta ilusi칩n **virtualizando** la CPU.

Al ejecutar un proceso, detenerlo y luego ejecutar otro, y as칤 sucesivamente, el OS puede promover la ilusi칩n de que existen muchas CPUs virtuales cuando en realidad solo hay una CPU f칤sica (o algunas). Esta t칠cnica b치sica, conocida como compartici칩n de tiempo (time sharing) de la CPU, permite a los usuarios ejecutar tantos procesos concurrentes como deseen; el costo potencial es el rendimiento, ya que cada proceso se ejecutar치 m치s lentamente si la(s) CPU(s) deben compartirse.

---
### TIP: Usar time sharing (space sharing)
El tiempo compartido es una tecnica b치sica usada por un SO para compartir un recurso. Al permitir que el recurso sea usado un ratito por una entidad y luego otro ratito por otra, y as칤 sucesivamente, el recurso en cuestion (por ejemplo, la CPU, o un enlace de una red) puede ser compartido por muchos. La contrapartida del tiempo compartido es el espacio compartido, donde un recurso se divide (en el espacio) entre aquellos que deseen utilizarlo. Por ejemplo, el espacio en disco es naturalmente un recurso de espacio compartido; una vez que se asigna un bloque a un archivo, normalmente no se asigna a otro archivo hasta que el usuario elimina el archivo original.

---

Para implementar la virtualizacion de la CPU, y para implementarla bien, el SO necesitara tanto maquinaria de bajo nivel como inteligencia de alto nivel. A la maquinaria de bajo nivel la llamamos mecanismos; los mecanismos son m칠todos o protocolos de bajo nivel que implementan una parte de la funcionalidad necesaria. Por ejemplo, mas adelante aprenderemos c칩mo implementar un  패cambio de contexto, que le da al SO la capacidad de dejar de ejecutar un pro- grama y empezar a ejecutar otro en una CPU determinada.

Encima de estos mecanismos reside parte de la inteligencia del SO, en forma de pol칤ticas. Las pol칤ticas son algoritmos para tomar algun tipo de decisi칩n dentro del SO. Por ejemplo, dado un n칰mero de programas posibles para ejecutar en una CPU, 쯤ue programa deber칤a ejecutar el SO? Una pol칤tica de planificaci칩n en el SO tomar치 esta decision, probablemente utilizando informaci칩n hist칩rica (por ejemplo, 쯤ue programa se ha ejecutado m치s en el ultimo minuto?), conocimiento de la carga de trabajo (por ejemplo, que tipos de programas se ejecutan) y metricas de rendimiento (por ejemplo, 쯘l sistema esta optimizando el rendimiento interactivo o el rendimiento de procesamiento?) para tomar su decision.

### La abstracci칩n: Un proceso

Para entender lo que constituye un **proceso**, tenemos que entender su estado: lo que un programa puede leer o actualizar cuando se est치 ejecutando.

- Un componente obvio del estado que comprende un proceso es su memoria. Las instrucciones se encuentran en la memoria; los datos que el programa en ejecuci칩n lee y escribe tambi칠n se encuentran en la memoria. El proceso puede direccionar la memoria (**espacio de direcciones**).

- Los registros forman parte del estado de un proceso; muchas instrucciones leen o actualizan expl칤citamente los registros y, por lo tanto, es evidente que son importantes para la ejecuci칩n del proceso.

---
### Tip: Separar pol칤ticas y mecanismos

En muchos sistemas operativos, un paradigma de dise침o com칰n es **separar** las pol칤ticas de alto nivel de sus mecanismos de bajo nivel. 
- Se puede pensar en el **mecanismo** como una forma de proporcionar la respuesta del `c칩mo` sobre un sistema; por ejemplo, 쯖칩mo realiza un sistema operativo un cambio de contexto? 
- La pol칤tica proporciona la respuesta del `cu치l`; por ejemplo, 쯖u치l proceso deber 패캼a ejecutar el sistema operativo en este momento? Separarlos permite cambiar facilmente las pol칤ticas sin tener que repensar el mecanismo y, por lo tanto, es una forma de modularidad, un principio general de dise침o de software.

---

Registros importantes que forman parte del estado de un proceso:
- **Program Counter**.
- **Stack Pointer**.
- **Frame Pointer**.

Los programas tambi칠n suelen acceder a dispositivos de almacenamiento persistente.

### La API de los procesos

- Crear: m칠todo para crear procesos.
- Destruir: destrucci칩n forzosa de procesos.
- Esperar: A veces es 칰til esperar a que un proceso deje de ejecutarse, se suele proporcionar alg칰n tipo de interfaz de espera.
- Controles varios: Hay otros tipos de control posibles, entre ellos suspender un proceso para luego reanudarlo, enviar se침ales a un proceso, etc.
- Estado: Normalmente tambi칠n hay interfaces para obtener informaci칩n sobre el estado de un proceso, como el tiempo que lleva en ejecuci칩n o el estado en el que se encuentra.

### Creaci칩n de procesos: Un poco m치s detallado

Lo primero que el OS debe hacer para ejecutar un programa es cargar su c칩digo y cualquier dato est치tico (por ejemplo, variables inicializadas) en la memoria, dentro del espacio de direcciones del proceso. Los programas residen inicialmente en el disco (o, en algunos sistemas modernos, en SSDs basados en flash) en alg칰n tipo de formato ejecutable; por lo tanto, el proceso de cargar un programa y datos est치ticos en la memoria requiere que el OS lea esos bytes del disco y los coloque en alg칰n lugar de la memoria.

En los primeros (o simples) sistemas operativos, el proceso de carga se realizaba de manera **eager** (apresurada), es decir, todo de una vez antes de ejecutar el programa.

Los sistemas operativos modernos realizan el proceso de forma "lazy" (perezoso), es decir, cargando piezas de c칩digo o datos solo cuando son necesarios durante la ejecuci칩n del programa.

Para comprender realmente c칩mo funciona la carga "lazy" de piezas de c칩digo y datos, tendr치s que entender m치s sobre los mecanismos de paginaci칩n e intercambio (paging and swapping)

Antes de ejecutar cualquier cosa, el OS claramente debe hacer algo de trabajo para llevar los bits importantes del programa desde el disco hasta la memoria.

Una vez que el c칩digo y los datos est치ticos est치n cargados en la memoria, hay algunas otras cosas que el OS necesita hacer antes de ejecutar el proceso. Se debe asignar algo de memoria para la pila de ejecuci칩n del programa (o simplemente stack).


El OS tambi칠n puede asignar algo de memoria para el heap del programa. En los programas en C, el heap se utiliza para datos que se solicitan din치micamente de manera expl칤cita; los programas solicitan dicho espacio llamando a `malloc()` y lo liberan llamando a `free()`. El heap es necesario para estructuras de datos como listas enlazadas, tablas hash, 치rboles y otras estructuras de datos interesantes. El heap ser치 peque침o al principio; a medida que el programa se ejecuta y solicita m치s memoria a trav칠s de la API de la biblioteca `malloc()`, el OS puede intervenir y asignar m치s memoria al proceso para ayudar a satisfacer dichas solicitudes.

- El OS tambi칠n realizar치 algunas tareas de inicializaci칩n adicionales, particularmente relacionadas con la entrada/salida (I/O)


Al cargar el c칩digo y los datos est치ticos en la memoria, al crear e inicializar una pila y al realizar otras tareas relacionadas con la configuraci칩n de I/O, el OS finalmente ha preparado el escenario para la ejecuci칩n del programa. Ahora le queda una 칰ltima tarea: iniciar la ejecuci칩n del programa en su punto de entrada, es decir, en `main()`. Al saltar a la rutina `main()`, el OS transfiere el control de la CPU al proceso reci칠n creado, y as칤 el programa comienza.

### Estados de los procesos
Un proceso puede estar en uno de los tres estados:
- **Running (Corriendo)**: Proceso en ejecuci칩n en un procesador. Ejecuci칩n de instrucciones.
- **Ready (Listo)**: Listo para ejecutarse, pero por alg칰n motivo el SO no ha optado por hacerlo.
- **Blocked (Bloqueado)**: Si un proceso esta bloqueado, ha realizado alg칔n tipo de operacion que hace que no este listo para ejecutarse hasta que ocurra algun otro evento.

<br>

<div align="center"><img src="imgs/image.png"></div>

<br>

Pasar de **ready** a **running** significa que un proceso ha sido **scheduled**. Ser movido de **running** a **ready** significa que el proceso va a ser **descheduled**.

Notar que hay muchas decisiones que debe tomar el SO, incluso en este ejemplo simple. Primero, el sistema tuvo que decidir ejecutar Proceso1 mientras Proceso_0 emit칤a una E/S; hacerlo mejora la utilizacion de los recursos al mantener la CPU ocupada. En segundo lugar, el sistema decidio no volver a cambiar a Proceso_0 cuando se completo su E/S; no est치 claro si esta es una buena decisi칩n o no.  Este tipo de decisiones las toma el scheduler (planificador) del sistema operativo,

### Estructura de datos

- Nuevo estado, **proceso zombie**: A veces, un sistema tendr치 un estado inicial en el que se encuentra el proceso cuando se est치 creando. Adem치s, un proceso podr칤a ser colocado en un estado final donde ha salido, pero a칰n no ha sido limpiado. 

Este estado final puede ser 칰til, ya que permite que otros procesos (generalmente el padre que cre칩 el proceso) examinen el c칩digo de retorno del proceso y vean si el proceso reci칠n finalizado se ejecut칩 con 칠xito (generalmente, los programas devuelven cero en sistemas basados en UNIX cuando han completado una tarea con 칠xito, y un valor distinto de cero en caso contrario). Cuando termina, el padre realizar치 una llamada final (por ejemplo, wait()) para esperar la finalizaci칩n del hijo y tambi칠n para indicar al OS que puede limpiar cualquier estructura de datos relevante que hac칤a referencia al proceso que ahora est치 extinto.


## Interludio: API de procesos
En este interludio, discutimos la creaci칩n de procesos en sistemas UNIX. UNIX presenta una de las formas m치s intrigantes de crear un nuevo proceso con un par de llamadas al sistema: `fork()` y `exec()`. Una tercera rutina, `wait()`, puede ser utilizada por un proceso que desee esperar a que un proceso que ha creado termine.

> CRUX: C칩mo crear y controlar procesos: 쯈u칠 interfaces deber칤a presentar el OS para la creaci칩n y control de procesos? 쮺칩mo deber칤an dise침arse estas interfaces para habilitar una funcionalidad poderosa, facilidad de uso y alto rendimiento?

### fork() System Call
La llamada al sistema fork() se utiliza para crear un nuevo proceso. Sin embargo, debes estar advertido: ciertamente es la rutina m치s extra침a que jam치s llamar치s. El proceso que se crea es una copia (casi) exacta del proceso que lo llam칩. Espec칤ficamente, aunque ahora tiene su propia copia del espacio de direcciones (es decir, su propia memoria privada), sus propios registros, su propio PC, etc. Cuando se crea el proceso hijo, ahora hay dos procesos activos en el sistema que nos importan: el padre y el hijo. Suponiendo que estamos ejecutando en un sistema con una sola CPU (por simplicidad), en ese punto podr칤a ejecutarse el hijo o el padre. El planificador de la CPU, un tema que discutiremos con gran detalle pronto, determina qu칠 proceso se ejecuta en un momento dado; dado que el planificador es complejo, generalmente no podemos hacer suposiciones fuertes sobre lo que elegir치 hacer, y por lo tanto, qu칠 proceso se ejecutar치 primero. Este no determinismo, como resulta, conduce a algunos problemas interesantes, particularmente en programas multihilo; por lo tanto, veremos mucho m치s no determinismo cuando estudiemos concurrencia en la segunda parte del libro.

### The wait() System Call
Hasta ahora, no hemos hecho mucho: solo crear un hijo que imprime un mensaje y sale. A veces, resulta bastante 칰til que un proceso padre espere a que un proceso hijo termine lo que est치 haciendo. Esta tarea se logra con la llamada al sistema wait() (o su versi칩n m치s completa waitpid()) En este ejemplo (p2.c), el proceso padre llama a wait() para retrasar su ejecuci칩n hasta que el hijo termine de ejecutarse. Cuando el hijo finaliza, wait() regresa el control al padre. Al agregar una llamada a wait() en el c칩digo anterior, la salida se vuelve determinista. Incluso cuando el padre se ejecuta primero, espera educadamente a que el hijo termine de ejecutarse, luego wait() regresa, y entonces el padre imprime su mensaje.

### exec() System Call
una 칰ltima y crucial pieza de la API de creaci칩n de procesos es la llamada al sistema exec(). Esta llamada al sistema es 칰til cuando quieres ejecutar un programa que es diferente al programa llamante. Por ejemplo, llamar a fork() solo es 칰til si deseas seguir ejecutando copias del mismo programa. Sin embargo, a menudo deseas ejecutar un programa diferente; exec()

```C
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf("hello (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) { // fork fall칩; salir
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // hijo (nuevo proceso)
        printf("child (pid:%d)\n", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup("wc"); // programa: "wc"
        myargs[1] = strdup("p3.c"); // argumento: archivo de entrada
        myargs[2] = NULL; // marcar el final del array
        execvp(myargs[0], myargs); // ejecuta word count
        printf("esto no deber칤a imprimirse");
    } else { // el padre sigue por este camino
        int rc_wait = wait(NULL);
        printf("parent of %d (rc_wait:%d) (pid:%d)\n", rc, rc_wait, (int) getpid());
    }
    return 0;
}
```

La llamada al sistema fork() es extra침a; su compa침ero en el crimen, exec(), tampoco es tan normal. Lo que hace: dado el nombre de un ejecutable (por ejemplo, wc), y algunos argumentos (por ejemplo, p3.c), carga el c칩digo (y datos est치ticos) de ese ejecutable y sobrescribe su segmento de c칩digo actual (y datos est치ticos actuales) con 칠l; el heap, la pila y otras partes del espacio de memoria del programa se re-inicializan. Luego, el sistema operativo simplemente ejecuta ese programa, pasando cualquier argumento como el argv de ese proceso. As칤, no crea un nuevo proceso; m치s bien, transforma el programa que se est치 ejecutando (anteriormente p3) en un programa diferente (wc). Despu칠s de exec() en el hijo, es casi como si p3.c nunca se hubiera ejecutado; una llamada exitosa a exec() nunca regresa.

### 쯇or qu칠? Motivando a la API
Por supuesto, una gran pregunta que podr칤as tener es: 쯣or qu칠 construir una interfaz tan extra침a para lo que deber칤a ser el acto simple de crear un nuevo proceso? Bueno, resulta que la separaci칩n de fork() y exec() es esencial para construir un shell en UNIX, porque permite que el shell ejecute c칩digo despu칠s de la llamada a fork() pero antes de la llamada a exec(). Este c칩digo puede alterar el entorno del programa que est치 a punto de ejecutarse, lo que permite construir f치cilmente una variedad de caracter칤sticas interesantes.

El shell es solo un programa de usuario. Te muestra un prompt y luego espera que escribas algo en 칠l. Luego escribes un comando (es decir, el nombre de un programa ejecutable, m치s cualquier argumento); en la mayor칤a de los casos, el shell averigua d칩nde se encuentra el ejecutable en el sistema de archivos, llama a fork() para crear un nuevo proceso hijo que ejecute el comando, llama a alguna variante de exec() para ejecutar el comando, y luego espera a que el comando termine llamando a wait(). Cuando el hijo termina, el shell regresa de wait() y vuelve a imprimir un prompt, listo para tu pr칩ximo comando.

La separaci칩n de fork() y exec() permite al shell hacer un mont칩n de cosas 칰tiles con relativa facilidad. Por ejemplo:
```shell
wc p3.c > newfile.txt
```
En el ejemplo anterior, la salida del programa wc se redirige al archivo de salida newfile.txt (el signo mayor que indica dicha redirecci칩n). La forma en que el shell logra esta tarea es bastante simple: cuando se crea el hijo, antes de llamar a exec(), el shell (espec칤ficamente, el c칩digo ejecutado en el proceso hijo) cierra la salida est치ndar y abre el archivo newfile.txt. Al hacer esto, cualquier salida del programa que est치 a punto de ejecutarse, wc, se env칤a al archivo en lugar de a la pantalla (los descriptores de archivos abiertos se mantienen abiertos a trav칠s de la llamada a exec(), lo que permite este comportamiento).

La Figura 5.4 muestra un programa que hace exactamente esto. La raz칩n por la que esta redirecci칩n funciona se debe a una suposici칩n sobre c칩mo el sistema operativo gestiona los descriptores de archivos. Espec칤ficamente, los sistemas UNIX comienzan a buscar descriptores de archivos libres desde cero. En este caso, STDOUT_FILENO ser치 el primero disponible y, por lo tanto, se asignar치 cuando se llame a open(). Las escrituras subsecuentes del proceso hijo al descriptor de archivo de salida est치ndar, por ejemplo, mediante rutinas como printf(), se dirigir치n autom치ticamente al archivo reci칠n abierto en lugar de a la pantalla.

Notar치s (al menos) dos detalles interesantes sobre esta salida. Primero, cuando se ejecuta p4, parece que no ha sucedido nada; el shell simplemente imprime el prompt de comando y est치 inmediatamente listo para tu pr칩ximo comando. Sin embargo, ese no es el caso; el programa p4 realmente llam칩 a fork() para crear un nuevo hijo y luego ejecut칩 el programa wc mediante una llamada a execvp(). No ves ninguna salida en la pantalla porque se ha redirigido al archivo p4.output. Segundo, puedes ver que cuando usamos cat para ver el archivo de salida, se encuentra toda la salida esperada de la ejecuci칩n de wc.

Por ahora, basta con decir que la combinaci칩n de fork()/exec() es una manera poderosa de crear y manipular procesos.

### Process Control and Users
M치s all치 de fork(), exec() y wait(), existen muchas otras interfaces para interactuar con procesos en sistemas UNIX. Por ejemplo, la llamada al sistema kill() se utiliza para enviar se침ales a un proceso, incluyendo directivas para pausar, finalizar, y otras 칩rdenes 칰tiles. Para mayor comodidad, en la mayor칤a de los shells de UNIX, ciertas combinaciones de teclas est치n configuradas para enviar una se침al espec칤fica al proceso que se est치 ejecutando; por ejemplo, control-c env칤a un SIGINT (interrupci칩n) al proceso (normalmente termin치ndolo), y control-z env칤a una se침al SIGTSTP (stop), pausando as칤 el proceso en mitad de su ejecuci칩n (puedes reanudarlo m치s tarde con un comando, por ejemplo, el comando fg que se encuentra en muchos shells). Todo el subsistema de se침ales proporciona una infraestructura rica para entregar eventos externos a procesos, incluyendo formas de recibir y procesar esas se침ales dentro de procesos individuales, as칤 como formas de enviar se침ales a procesos individuales o a grupos enteros de procesos.

Para utilizar esta forma de comunicaci칩n, un proceso debe usar la llamada al sistema signal() para "capturar" varias se침ales; al hacerlo, se asegura de que cuando una se침al particular se entregue a un proceso, este suspender치 su ejecuci칩n normal y ejecutar치 una porci칩n espec칤fica de c칩digo en respuesta a la se침al. Puedes leer en otra parte [SR05] para aprender m치s sobre las se침ales y sus m칰ltiples complejidades.

Esto naturalmente plantea la pregunta: 쯤ui칠n puede enviar una se침al a un proceso y qui칠n no? Generalmente, los sistemas que usamos pueden ser utilizados por m칰ltiples personas al mismo tiempo; si una de estas personas pudiera enviar arbitrariamente se침ales como SIGINT (para interrumpir un proceso, probablemente termin치ndolo), la usabilidad y seguridad del sistema se ver칤an comprometidas. Como resultado, los sistemas modernos incluyen una concepci칩n s칩lida de la noci칩n de un usuario.
 * El usuario, despu칠s de ingresar una contrase침a para establecer credenciales, inicia sesi칩n para obtener acceso a los recursos del sistema.
 * El usuario puede entonces lanzar uno o muchos procesos y ejercer control total sobre ellos (pausarlos, matarlos, etc.).
 * Los usuarios generalmente solo pueden controlar sus propios procesos; es el trabajo del sistema operativo distribuir los recursos (como CPU, memoria y disco) a cada usuario (y sus procesos) para cumplir con los objetivos generales del sistema.

### Herramientas 칰tiles
Existen muchas herramientas de l칤nea de comandos que tambi칠n son 칰tiles. Por ejemplo, el comando ps te permite ver qu칠 procesos est치n en ejecuci칩n; consulta las p치ginas de manual para obtener algunas banderas 칰tiles que puedes pasar a ps. La herramienta top tambi칠n es bastante 칰til, ya que muestra los procesos del sistema y cu치ntos recursos de CPU y otros est치n consumiendo. Curiosamente, muchas veces cuando ejecutas top, este afirma ser el que m치s recursos consume; quiz치s es un poco egoc칠ntrico. El comando kill se puede usar para enviar se침ales arbitrarias a los procesos, al igual que el comando killall, que es un poco m치s amigable para el usuario. Aseg칰rate de usarlos con cuidado; si accidentalmente matas tu gestor de ventanas, la computadora frente a ti puede volverse bastante dif칤cil de usar.

Finalmente, hay muchos tipos diferentes de medidores de CPU que puedes usar para obtener una comprensi칩n r치pida de la carga en tu sistema; por ejemplo, siempre mantenemos MenuMeters (de Raging Menace Software) funcionando en nuestras barras de herramientas de Macintosh, para que podamos ver cu치nto CPU se est치 utilizando en cualquier momento. En general, cuanta m치s informaci칩n tengas sobre lo que est치 sucediendo, mejor.

### Aside: El superusuario (ROOT)
Un sistema generalmente necesita un usuario que pueda administrar el sistema y que no est칠 limitado de la misma manera que la mayor칤a de los usuarios. Dicho usuario deber칤a poder matar un proceso arbitrario (por ejemplo, si est치 abusando del sistema de alguna manera), aunque ese proceso no haya sido iniciado por este usuario. Tal usuario tambi칠n deber칤a poder ejecutar comandos poderosos como shutdown (que, como es de esperarse, apaga el sistema). En los sistemas basados en UNIX, estas habilidades especiales se otorgan al superusuario (a veces llamado root). Mientras que la mayor칤a de los usuarios no pueden matar los procesos de otros usuarios, el superusuario s칤 puede. Ser root es como ser Spider-Man: con un gran poder viene una gran responsabilidad. Por lo tanto, para aumentar la seguridad (y evitar errores costosos), generalmente es mejor ser un usuario regular; si necesitas ser root, procede con cautela, ya que todos los poderes destructivos del mundo de la computaci칩n est치n ahora a tu alcance.