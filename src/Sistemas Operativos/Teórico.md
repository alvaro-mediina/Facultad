# 游눹 Te칩rico de Sistemas Operativos 游

En este archivo encontrar치s un resumen o algunas ideas sobre el libro OSTEP (Operating Systems: Three Easy Pieces) y otros temas relacionados con sistemas operativos.

Como la materia se divide en 3 partes, tambi칠n dividir칠 este archivo en 3 partes, una para cada parte del libro.

Enjoy :D

# Indice

- [Introducci칩n](#introducci칩n)
  - [Introducci칩n a los Sistemas Operativos](#introducci칩n-a-los-sistemas-operativos)
  - [Virtualizando la CPU](#virtualizando-la-cpu)
  - [Virtualizando la Memoria](#virtualizando-la-memoria)
  - [Concurrencia](#concurrencia)
  - [Persistencia](#persistencia)
  - [Desiciones de dise침o](#desiciones-de-dise침o)
  - [Un poco de historia](#un-poco-de-historia)
- [Virtualizaci칩n](#virtualizacion)
  - [Dialogo](#dialogo)
  - [Procesos](#procesos)
  - [Interludio: API de procesos](#interludio-api-de-procesos)
  - [Ejecuci칩n Directa Limitada](#ejecuci칩n-directa-limitada)
  - [Planificaci칩n de la CPU](#planificaci칩n-de-la-cpu)

# Introducci칩n

Las tres piezas f치ciles se refieren a los tres elementos tem치ticos principales en los que se organiza el libro: virtualizaci칩n, concurrencia y persistencia. Al discutir estos conceptos, terminaremos hablando de la mayor칤a de las cosas importantes que hace un sistema operativo; con suerte, tambi칠n se divertir치n en el camino.

- El primero es el `crux` del problema. Cada vez que tratamos de resolver un problema, primero intentamos declarar cu치l es el tema m치s importante; dicho crux del problema se se침ala expl칤citamente en el texto, y esperamos que se resuelva a trav칠s de las t칠cnicas, algoritmos e ideas presentadas en el resto del texto.
- En muchos lugares, explicaremos c칩mo funciona un sistema mostrando su comportamiento a lo largo del tiempo. Estas l칤neas de tiempo son la esencia de la comprensi칩n; si sabes qu칠 ocurre, estar치s en camino a entender verdaderamente c칩mo opera la memoria virtual.

- Si comprendes lo que sucede cuando un sistema de archivos con journaling escribe un bloque en el disco, habr치s dado los primeros pasos hacia el dominio de los sistemas de almacenamiento.

- Al principio de cada secci칩n principal, primero presentaremos una `abstracci칩n` que un sistema operativo proporciona, y luego trabajaremos en los cap칤tulos siguientes sobre los mecanismos, pol칤ticas y otros apoyos necesarios para proporcionar esa abstracci칩n.
  - Las abstracciones son fundamentales en todos los aspectos de la Ciencia de la Computaci칩n, por lo que no es sorprendente que tambi칠n sean esenciales en los sistemas operativos.

> **Consejo**: Asiste a clase, para escuchar al profesor presentar el material. Luego, al final de cada semana, lee estas notas, para ayudar a que las ideas se asienten un poco mejor en tu mente. Por supuesto, alg칰n tiempo despu칠s (pista: antes del examen), vuelve a leer las notas para consolidar tu conocimiento. Por supuesto, tu profesor sin duda asignar치 algunas tareas y proyectos, as칤 que deber칤as hacerlos; en particular, hacer proyectos donde escribas c칩digo real para resolver problemas reales es la mejor manera de poner en pr치ctica las ideas de estas notas.

## Introducci칩n a los Sistemas Operativos

> **El CRUX del problema: C칩mo virtualizar los recursos**: El porqu칠 el sistema operativo hace esto no es la pregunta principal, ya que la respuesta deber칤a ser obvia: hace que el sistema sea m치s f치cil de usar. Por lo tanto, nos enfocamos en el c칩mo: 쯤u칠 mecanismos y pol칤ticas implementa el sistema operativo para lograr la virtualizaci칩n? 쮺칩mo lo hace de manera eficiente? 쯈u칠 soporte de hardware es necesario?

### Virtualizando la CPU

Si s칩lo tenemos un procesador 쮺칩mo ocurre la magia de correr programas al mismo tiempo? Resulta que el sistema operativo, con algo de ayuda del hardware, es el encargado de crear esta ilusi칩n, es decir, la ilusi칩n de que el sistema tiene un n칰mero muy grande de CPUs virtuales. Convertir un solo CPU (o un peque침o conjunto de ellos) en un n칰mero aparentemente infinito de CPUs y, por lo tanto, permitir que muchos programas se ejecuten aparentemente al mismo tiempo es lo que llamamos virtualizaci칩n de la CPU.

Por supuesto, para ejecutar programas, detenerlos y, en general, indicarle al sistema operativo qu칠 programas ejecutar, deben existir algunas interfaces (APIs) que puedes usar para comunicar tus deseos al sistema operativo. Hablaremos sobre estas APIs a lo largo del libro; de hecho, son la principal forma en que la mayor칤a de los usuarios interact칰a con los sistemas operativos.

### Virtualizando la Memoria

Ahora consideremos la memoria. El modelo de memoria f칤sica presentado por las m치quinas modernas es muy simple. La memoria es simplemente un array de bytes; para leer la memoria, se debe especificar una direcci칩n para poder acceder a los datos almacenados all칤; para escribir (o actualizar) memoria, tambi칠n se debe especificar los datos a escribir en la direcci칩n dada.

La memoria se accede todo el tiempo cuando un programa est치 en ejecuci칩n. Un programa mantiene todas sus estructuras de datos en memoria y accede a ellas mediante diversas instrucciones, como cargas y almacenamientos, o otras instrucciones expl칤citas que acceden a la memoria para realizar su trabajo. No olvides que cada instrucci칩n del programa tambi칠n est치 en memoria; por lo tanto, la memoria se accede en cada recuperaci칩n de instrucci칩n.

```C
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <assert.h>
#include <sys/time.h>
#include <time.h>

void Spin(int seconds) {
    time_t start = time(NULL);
    while (time(NULL) - start < seconds) {
        // Bucle vac칤o que consume tiempo
    }
}

int main(int argc, char *argv[]){
    int *p = malloc(sizeof(int)); // a1
    assert(p != NULL);
    printf("(%d) address pointed to by p: %p\n", getpid(), p); // a2
    *p = 0; // a3
    while (1) {
        Spin(1);
        *p = *p + 1;
        printf("(%d) p: %d\n", getpid(), *p); // a4
    }
    return 0;
}
```

El programa hace un par de cosas. Primero, asigna algo de memoria (l칤nea a1). Luego, imprime la direcci칩n de la memoria (a2) y, a continuaci칩n, coloca el n칰mero cero en la primera posici칩n de la memoria reci칠n asignada (a3). Finalmente, entra en un bucle, retras치ndose durante un segundo e incrementando el valor almacenado en la direcci칩n contenida en p. Con cada declaraci칩n de impresi칩n, tambi칠n muestra lo que se llama el identificador del proceso (PID) del programa en ejecuci칩n. Este PID es 칰nico para cada proceso en ejecuci칩n. Nuevamente, este primer resultado no es muy interesante. La memoria reci칠n asignada est치 en la direcci칩n 0x200000. A medida que el programa se ejecuta, actualiza lentamente el valor y muestra el resultado.

```bash
$ gcc -o mem mem.c
[1] 15998
(15999) address pointed to by p: 0x5b34db0ce2a0
(15998) address pointed to by p: 0x578a0f4c02a0
(15999) p: 1
(15998) p: 1
(15998) p: 2
(15999) p: 2
(15999) p: 3
(15998) p: 3
(15999) p: 4
(15998) p: 4
(15999) p: 5
(15998) p: 5
(15998) p: 6
(15999) p: 6
(15999) p: 7
(15998) p: 7
(15998) p: 8
(15999) p: 8
(15999) p: 9
(15998) p: 9

```

Ahora, ejecutamos varias instancias de este mismo programa para ver qu칠 sucede (Figura 2.4). Vemos en el ejemplo que cada programa en ejecuci칩n ha asignado memoria en la misma direcci칩n (0x578a0f4c02a0), 춰y sin embargo, cada uno parece estar actualizando el valor en 0x578a0f4c02a0 de forma independiente! Es como si cada programa en ejecuci칩n tuviera su propia memoria privada, en lugar de compartir la misma memoria f칤sica con otros programas en ejecuci칩n. De hecho, eso es exactamente lo que est치 sucediendo aqu칤, ya que el sistema operativo est치 virtualizando la memoria. Cada proceso accede a su propio espacio de direcciones virtuales privado (a veces simplemente llamado su espacio de direcciones), que el sistema operativo mapea de alguna manera a la memoria f칤sica de la m치quina. Una referencia de memoria dentro de un programa en ejecuci칩n no afecta el espacio de direcciones de otros procesos (o del propio sistema operativo); en lo que respecta al programa en ejecuci칩n, tiene la memoria f칤sica solo para s칤 mismo. La realidad, sin embargo, es que la memoria f칤sica es un recurso compartido, gestionado por el sistema operativo.

### Concurrencia

Usamos este t칠rmino conceptual para referirnos a una serie de problemas que surgen y deben ser abordados cuando se trabaja en muchas cosas al mismo tiempo (es decir, concurrentemente) en el mismo programa. Los problemas de concurrencia surgieron primero dentro del propio sistema operativo; como puedes ver en los ejemplos anteriores sobre virtualizaci칩n, el sistema operativo est치 manejando muchas cosas a la vez, ejecutando primero un proceso, luego otro, y as칤 sucesivamente. Resulta que hacer esto lleva a problemas profundos e interesantes

> El CRUX del problema:
> Cuando hay muchos hilos ejecut치ndose concurrentemente dentro del mismo espacio de memoria, 쯖칩mo podemos construir un programa que funcione correctamente? 쯈u칠 primitivas se necesitan del sistema operativo? 쯈u칠 mecanismos deben proporcionar el hardware? 쮺칩mo podemos usarlos para resolver los problemas de concurrencia?

### Persistencia

El tercer tema principal del curso es la persistencia. En la memoria del sistema, los datos pueden perderse f치cilmente, ya que dispositivos como la DRAM almacenan valores de manera vol치til; cuando se corta la energ칤a o el sistema falla, cualquier dato en memoria se pierde. Por lo tanto, necesitamos hardware y software capaces de almacenar datos de manera persistente.

El software en el sistema operativo que generalmente gestiona el disco se llama el sistema de archivos; por lo tanto, es responsable de almacenar cualquier archivo que el usuario cree de manera confiable y eficiente en los discos del sistema.

A diferencia de las abstracciones proporcionadas por el sistema operativo para la CPU y la memoria, el sistema operativo no crea un disco virtualizado privado para cada aplicaci칩n. M치s bien, se asume que, a menudo, los usuarios querr치n compartir informaci칩n que est치 en archivos.

### Desiciones de dise침o

Un objetivo en el dise침o e implementaci칩n de un sistema operativo es proporcionar un alto rendimiento; otra forma de decirlo es que nuestro objetivo es minimizar los sobrecostos del OS.

Otro objetivo ser치 proporcionar protecci칩n entre aplicaciones, as칤 como entre el OS y las aplicaciones. Debido a que queremos permitir que muchos programas se ejecuten al mismo tiempo, queremos asegurarnos de que el comportamiento malicioso o accidentalmente incorrecto de uno no da침e a los dem치s; ciertamente no queremos que una aplicaci칩n pueda da침ar el propio OS (ya que eso afectar칤a a todos los programas que se ejecutan en el sistema). La protecci칩n es el coraz칩n de uno de los principales principios subyacentes de un sistema operativo, que es el de aislamiento; aislar procesos unos de otros es clave para la protecci칩n y, por lo tanto, subyace en gran parte de lo que un OS debe hacer.

### Un poco de historia

#### Primeros Sistemas Operativos: Solo Bibliotecas

En sus inicios, los sistemas operativos (OS) eran bastante rudimentarios, funcionando esencialmente como bibliotecas de funciones comunes. En lugar de que cada programador escribiera c칩digo para manejar I/O de bajo nivel, el "OS" proporcionaba APIs para facilitar el desarrollo. En estos sistemas de mainframe antiguos, solo se ejecutaba un programa a la vez, controlado por un operador humano. Mucho de lo que hoy consideramos funciones b치sicas de un OS (como decidir el orden de ejecuci칩n de trabajos) lo hac칤a este operador. Este modo de procesamiento se conoc칤a como procesamiento por lotes (batch processing), donde una serie de trabajos se configuraban y se ejecutaban en "lote" por el operador. Dado que era costoso permitir que un usuario interactuara directamente con la computadora, se utilizaba principalmente el procesamiento por lotes [BH00].

#### M치s All치 de las Bibliotecas: Protecci칩n

A medida que los sistemas operativos evolucionaron, asumieron un papel m치s central en la gesti칩n de las m치quinas. Un aspecto importante fue reconocer que el c칩digo ejecutado en nombre del OS deb칤a ser especial y tratado de manera diferente al c칩digo de aplicaci칩n normal. Permitir que cualquier aplicaci칩n leyera cualquier archivo en el disco compromet칤a la privacidad. Por lo tanto, se invent칩 la llamada a sistema (system call), un mecanismo que permiti칩 la transici칩n controlada al OS, elevando el nivel de privilegio del hardware. En contraste con una llamada a procedimiento, una llamada a sistema transfiere el control al OS mientras eleva el nivel de privilegio del hardware. Esto permiti칩 al OS tener acceso completo al hardware y realizar operaciones como solicitudes de I/O o gestionar memoria. Una vez completada la solicitud, el control se devuelve al usuario.

#### La Era del Multiprogramming

Con la llegada de las minicomputadoras, los sistemas operativos dieron un gran salto. Las m치quinas cl치sicas como la PDP de Digital Equipment hicieron que las computadoras fueran m치s asequibles, permitiendo que un grupo menor de personas dentro de una organizaci칩n tuviera su propia m치quina. Esto impuls칩 la actividad de desarrollo y la innovaci칩n en los sistemas operativos, especialmente con la multiprogramaci칩n. En lugar de ejecutar un solo trabajo a la vez, el OS cargaba m칰ltiples trabajos en memoria y cambiaba r치pidamente entre ellos para mejorar la utilizaci칩n del CPU. La necesidad de soportar multiprogramaci칩n y la superposici칩n en presencia de I/O e interrupciones llev칩 a importantes innovaciones en la protecci칩n de memoria y el manejo de la concurrencia. La introducci칩n del sistema operativo UNIX por Ken Thompson y Dennis Ritchie en Bell Labs fue un avance significativo, al simplificar y hacer m치s accesibles muchas ideas buenas de otros sistemas [O72, B+72, S68].

#### La Era Moderna

La llegada de las computadoras personales (PC) marc칩 una nueva era en la inform치tica. Las primeras PCs, como el Apple II y el IBM PC, se convirtieron en la fuerza dominante en la computaci칩n debido a su bajo costo. Sin embargo, los primeros sistemas operativos de PC, como DOS, olvidaron o nunca aprendieron las lecciones de las minicomputadoras, como la protecci칩n de memoria. Los primeros sistemas operativos de Mac (hasta la versi칩n 9) ten칤an un enfoque cooperativo para la programaci칩n, lo que permit칤a que un hilo atrapado en un bucle infinito pudiera tomar el control completo del sistema. Afortunadamente, con el tiempo, las caracter칤sticas avanzadas de los sistemas operativos de minicomputadoras comenzaron a integrarse en los sistemas de escritorio. Hoy en d칤a, sistemas como macOS, basado en UNIX, y Windows NT han adoptado muchas de las grandes ideas de la historia de la computaci칩n. Incluso los tel칠fonos m칩viles modernos, que ejecutan sistemas operativos como Linux, se asemejan m치s a los sistemas de minicomputadoras de los a침os 70 que a los PC de los a침os 80. Es gratificante ver c칩mo las buenas ideas del pasado contin칰an evolucionando y mejorando los sistemas modernos.

#### ASIDE: La importancia de UNIX

Es dif칤cil exagerar la importancia de UNIX en la historia de los sistemas operativos. Influenciado por sistemas anteriores, en particular el famoso sistema Multics del MIT, UNIX reuni칩 muchas ideas innovadoras y cre칩 un sistema tanto simple como poderoso. El principio unificador subyacente al UNIX original de "Bell Labs" era la construcci칩n de peque침os programas potentes que pod칤an conectarse entre s칤 para formar flujos de trabajo m치s grandes. El shell, donde se escriben los comandos, proporcionaba primitivas como los pipes (tuber칤as) para habilitar tal programaci칩n a nivel meta, facilitando la conexi칩n de programas para lograr una tarea m치s compleja.

Por ejemplo, para encontrar l칤neas en un archivo de texto que contengan la palabra "foo" y luego contar cu치ntas de esas l칤neas existen, se escribir칤a: grep foo file.txt | wc -l, utilizando as칤 los programas grep y wc (word count) para cumplir la tarea. El entorno UNIX era amigable tanto para programadores como para desarrolladores, proporcionando tambi칠n un compilador para el nuevo lenguaje de programaci칩n C. Facilitar que los programadores escribieran sus propios programas, as칤 como compartirlos, hizo que UNIX se volviera enormemente popular. Probablemente tambi칠n ayud칩 mucho que los autores distribuyeran copias gratuitamente a quien las solicitara, una forma temprana de software de c칩digo abierto.

Otra de las caracter칤sticas cr칤ticas fue la accesibilidad y legibilidad del c칩digo. Tener un kernel hermoso y peque침o escrito en C invitaba a otros a jugar con 칠l, agregando nuevas y geniales funcionalidades. Por ejemplo, un grupo emprendedor en Berkeley, liderado por Bill Joy, cre칩 una maravillosa distribuci칩n (la Berkeley Systems Distribution, o BSD) que inclu칤a subsistemas avanzados de memoria virtual, sistemas de archivos y redes. Joy luego cofund칩 Sun Microsystems.

Desafortunadamente, la expansi칩n de UNIX se vio un poco frenada cuando algunas empresas intentaron reclamar su propiedad y lucrar con 칠l, un resultado desafortunado (pero com칰n) cuando los abogados se involucran. Muchas empresas desarrollaron sus propias variantes: SunOS de Sun Microsystems, AIX de IBM, HPUX (conocido como "H-Pucks") de HP, e IRIX de SGI. Las disputas legales entre AT&T/Bell Labs y estos otros actores arrojaron una sombra sobre UNIX, y muchos se preguntaban si sobrevivir칤a, especialmente con la introducci칩n de Windows, que se apoder칩 de gran parte del mercado de PCs...

#### ASIDE: Y luego lleg칩 Linux

Afortunadamente para UNIX, un joven hacker finland칠s llamado Linus Torvalds decidi칩 escribir su propia versi칩n de UNIX, la cual se basaba en gran medida en los principios e ideas del sistema original, pero no en su base de c칩digo, evitando as칤 problemas legales. Torvalds cont칩 con la ayuda de muchas personas de todo el mundo y aprovech칩 las sofisticadas herramientas GNU que ya exist칤an [G85], y pronto naci칩 Linux (as칤 como el movimiento moderno de software de c칩digo abierto).

Con la llegada de la era de internet, la mayor칤a de las empresas (como Google, Amazon, Facebook y otras) optaron por usar Linux, ya que era gratuito y pod칤a modificarse f치cilmente para satisfacer sus necesidades; de hecho, es dif칤cil imaginar el 칠xito de estas nuevas compa침칤as si un sistema as칤 no hubiera existido. A medida que los tel칠fonos inteligentes se convirtieron en una plataforma dominante para los usuarios, Linux tambi칠n encontr칩 un basti칩n all칤 (a trav칠s de Android), por muchas de las mismas razones. Adem치s, Steve Jobs llev칩 consigo su entorno operativo basado en UNIX, NeXTStep, a Apple, lo que hizo que UNIX fuera popular en los escritorios (aunque muchos usuarios de la tecnolog칤a de Apple probablemente no sean conscientes de este hecho).

As칤, UNIX sigue vivo, m치s importante hoy que nunca. Los dioses de la computaci칩n, si crees en ellos, deber칤an ser agradecidos por este maravilloso resultado.

# Virtualizaci칩n de la CPU

## Procesos

Definici칩n informal: Programa en ejecuci칩n

El programa en s칤 mismo es una cosa sin vida: solo est치 all칤 en el disco, un monton de instrucciones (y quiz치s 패algunos datos est치ticos), esperando entrar en acci칩n. Es el sistema 패operativo el que toma estos bytes y los pone en marcha, transformando el programa en algo util.

---

### El problema en cuesti칩n:

쮺칩mo proporcionar la ilusi칩n de muchas CPU's? A pesar de que solo hay unas pocas CPUs f칤sicas disponibles, 쮺omo puede el sistema operativo proporcionar la ilusion de un suministro casi infinito de dichas CPUs?

---

El sistema operativo crea esta ilusi칩n **virtualizando** la CPU.

Al ejecutar un proceso, detenerlo y luego ejecutar otro, y as칤 sucesivamente, el OS puede promover la ilusi칩n de que existen muchas CPUs virtuales cuando en realidad solo hay una CPU f칤sica (o algunas). Esta t칠cnica b치sica, conocida como compartici칩n de tiempo (time sharing) de la CPU, permite a los usuarios ejecutar tantos procesos concurrentes como deseen; el costo potencial es el rendimiento, ya que cada proceso se ejecutar치 m치s lentamente si la(s) CPU(s) deben compartirse.

---

### TIP: Usar time sharing (space sharing)

El tiempo compartido es una tecnica b치sica usada por un SO para compartir un recurso. Al permitir que el recurso sea usado un ratito por una entidad y luego otro ratito por otra, y as칤 sucesivamente, el recurso en cuestion (por ejemplo, la CPU, o un enlace de una red) puede ser compartido por muchos. La contrapartida del tiempo compartido es el espacio compartido, donde un recurso se divide (en el espacio) entre aquellos que deseen utilizarlo. Por ejemplo, el espacio en disco es naturalmente un recurso de espacio compartido; una vez que se asigna un bloque a un archivo, normalmente no se asigna a otro archivo hasta que el usuario elimina el archivo original.

---

Para implementar la virtualizacion de la CPU, y para implementarla bien, el SO necesitara tanto maquinaria de bajo nivel como inteligencia de alto nivel. A la maquinaria de bajo nivel la llamamos mecanismos; los mecanismos son m칠todos o protocolos de bajo nivel que implementan una parte de la funcionalidad necesaria. Por ejemplo, mas adelante aprenderemos c칩mo implementar un 패cambio de contexto, que le da al SO la capacidad de dejar de ejecutar un pro- grama y empezar a ejecutar otro en una CPU determinada.

Encima de estos mecanismos reside parte de la inteligencia del SO, en forma de pol칤ticas. Las pol칤ticas son algoritmos para tomar algun tipo de decisi칩n dentro del SO. Por ejemplo, dado un n칰mero de programas posibles para ejecutar en una CPU, 쯤ue programa deber칤a ejecutar el SO? Una pol칤tica de planificaci칩n en el SO tomar치 esta decision, probablemente utilizando informaci칩n hist칩rica (por ejemplo, 쯤ue programa se ha ejecutado m치s en el ultimo minuto?), conocimiento de la carga de trabajo (por ejemplo, que tipos de programas se ejecutan) y metricas de rendimiento (por ejemplo, 쯘l sistema esta optimizando el rendimiento interactivo o el rendimiento de procesamiento?) para tomar su decision.

### La abstracci칩n: Un proceso

Para entender lo que constituye un **proceso**, tenemos que entender su estado: lo que un programa puede leer o actualizar cuando se est치 ejecutando.

- Un componente obvio del estado que comprende un proceso es su memoria. Las instrucciones se encuentran en la memoria; los datos que el programa en ejecuci칩n lee y escribe tambi칠n se encuentran en la memoria. El proceso puede direccionar la memoria (**espacio de direcciones**).

- Los registros forman parte del estado de un proceso; muchas instrucciones leen o actualizan expl칤citamente los registros y, por lo tanto, es evidente que son importantes para la ejecuci칩n del proceso.

---

### Tip: Separar pol칤ticas y mecanismos

En muchos sistemas operativos, un paradigma de dise침o com칰n es **separar** las pol칤ticas de alto nivel de sus mecanismos de bajo nivel.

- Se puede pensar en el **mecanismo** como una forma de proporcionar la respuesta del `c칩mo` sobre un sistema; por ejemplo, 쯖칩mo realiza un sistema operativo un cambio de contexto?
- La pol칤tica proporciona la respuesta del `cu치l`; por ejemplo, 쯖u치l proceso deber 패캼a ejecutar el sistema operativo en este momento? Separarlos permite cambiar facilmente las pol칤ticas sin tener que repensar el mecanismo y, por lo tanto, es una forma de modularidad, un principio general de dise침o de software.

---

Registros importantes que forman parte del estado de un proceso:

- **Program Counter**.
- **Stack Pointer**.
- **Frame Pointer**.

Los programas tambi칠n suelen acceder a dispositivos de almacenamiento persistente.

### La API de los procesos

- Crear: m칠todo para crear procesos.
- Destruir: destrucci칩n forzosa de procesos.
- Esperar: A veces es 칰til esperar a que un proceso deje de ejecutarse, se suele proporcionar alg칰n tipo de interfaz de espera.
- Controles varios: Hay otros tipos de control posibles, entre ellos suspender un proceso para luego reanudarlo, enviar se침ales a un proceso, etc.
- Estado: Normalmente tambi칠n hay interfaces para obtener informaci칩n sobre el estado de un proceso, como el tiempo que lleva en ejecuci칩n o el estado en el que se encuentra.

### Creaci칩n de procesos: Un poco m치s detallado

Lo primero que el OS debe hacer para ejecutar un programa es cargar su c칩digo y cualquier dato est치tico (por ejemplo, variables inicializadas) en la memoria, dentro del espacio de direcciones del proceso. Los programas residen inicialmente en el disco (o, en algunos sistemas modernos, en SSDs basados en flash) en alg칰n tipo de formato ejecutable; por lo tanto, el proceso de cargar un programa y datos est치ticos en la memoria requiere que el OS lea esos bytes del disco y los coloque en alg칰n lugar de la memoria.

En los primeros (o simples) sistemas operativos, el proceso de carga se realizaba de manera **eager** (apresurada), es decir, todo de una vez antes de ejecutar el programa.

Los sistemas operativos modernos realizan el proceso de forma "lazy" (perezoso), es decir, cargando piezas de c칩digo o datos solo cuando son necesarios durante la ejecuci칩n del programa.

Para comprender realmente c칩mo funciona la carga "lazy" de piezas de c칩digo y datos, tendr치s que entender m치s sobre los mecanismos de paginaci칩n e intercambio (paging and swapping)

Antes de ejecutar cualquier cosa, el OS claramente debe hacer algo de trabajo para llevar los bits importantes del programa desde el disco hasta la memoria.

Una vez que el c칩digo y los datos est치ticos est치n cargados en la memoria, hay algunas otras cosas que el OS necesita hacer antes de ejecutar el proceso. Se debe asignar algo de memoria para la pila de ejecuci칩n del programa (o simplemente stack).

El OS tambi칠n puede asignar algo de memoria para el heap del programa. En los programas en C, el heap se utiliza para datos que se solicitan din치micamente de manera expl칤cita; los programas solicitan dicho espacio llamando a `malloc()` y lo liberan llamando a `free()`. El heap es necesario para estructuras de datos como listas enlazadas, tablas hash, 치rboles y otras estructuras de datos interesantes. El heap ser치 peque침o al principio; a medida que el programa se ejecuta y solicita m치s memoria a trav칠s de la API de la biblioteca `malloc()`, el OS puede intervenir y asignar m치s memoria al proceso para ayudar a satisfacer dichas solicitudes.

- El OS tambi칠n realizar치 algunas tareas de inicializaci칩n adicionales, particularmente relacionadas con la entrada/salida (I/O)

Al cargar el c칩digo y los datos est치ticos en la memoria, al crear e inicializar una pila y al realizar otras tareas relacionadas con la configuraci칩n de I/O, el OS finalmente ha preparado el escenario para la ejecuci칩n del programa. Ahora le queda una 칰ltima tarea: iniciar la ejecuci칩n del programa en su punto de entrada, es decir, en `main()`. Al saltar a la rutina `main()`, el OS transfiere el control de la CPU al proceso reci칠n creado, y as칤 el programa comienza.

### Estados de los procesos

Un proceso puede estar en uno de los tres estados:

- **Running (Corriendo)**: Proceso en ejecuci칩n en un procesador. Ejecuci칩n de instrucciones.
- **Ready (Listo)**: Listo para ejecutarse, pero por alg칰n motivo el SO no ha optado por hacerlo.
- **Blocked (Bloqueado)**: Si un proceso esta bloqueado, ha realizado alg칔n tipo de operacion que hace que no este listo para ejecutarse hasta que ocurra algun otro evento.

<br>

<div align="center"><img src="imgs/image.png"></div>

<br>

Pasar de **ready** a **running** significa que un proceso ha sido **scheduled**. Ser movido de **running** a **ready** significa que el proceso va a ser **descheduled**.

Notar que hay muchas decisiones que debe tomar el SO, incluso en este ejemplo simple. Primero, el sistema tuvo que decidir ejecutar Proceso1 mientras Proceso_0 emit칤a una E/S; hacerlo mejora la utilizacion de los recursos al mantener la CPU ocupada. En segundo lugar, el sistema decidio no volver a cambiar a Proceso_0 cuando se completo su E/S; no est치 claro si esta es una buena decisi칩n o no. Este tipo de decisiones las toma el scheduler (planificador) del sistema operativo,

### Estructura de datos

- Nuevo estado, **proceso zombie**: A veces, un sistema tendr치 un estado inicial en el que se encuentra el proceso cuando se est치 creando. Adem치s, un proceso podr칤a ser colocado en un estado final donde ha salido, pero a칰n no ha sido limpiado.

Este estado final puede ser 칰til, ya que permite que otros procesos (generalmente el padre que cre칩 el proceso) examinen el c칩digo de retorno del proceso y vean si el proceso reci칠n finalizado se ejecut칩 con 칠xito (generalmente, los programas devuelven cero en sistemas basados en UNIX cuando han completado una tarea con 칠xito, y un valor distinto de cero en caso contrario). Cuando termina, el padre realizar치 una llamada final (por ejemplo, wait()) para esperar la finalizaci칩n del hijo y tambi칠n para indicar al OS que puede limpiar cualquier estructura de datos relevante que hac칤a referencia al proceso que ahora est치 extinto.

## Interludio: API de procesos

En este interludio, discutimos la creaci칩n de procesos en sistemas UNIX. UNIX presenta una de las formas m치s intrigantes de crear un nuevo proceso con un par de llamadas al sistema: `fork()` y `exec()`. Una tercera rutina, `wait()`, puede ser utilizada por un proceso que desee esperar a que un proceso que ha creado termine.

> CRUX: C칩mo crear y controlar procesos: 쯈u칠 interfaces deber칤a presentar el OS para la creaci칩n y control de procesos? 쮺칩mo deber칤an dise침arse estas interfaces para habilitar una funcionalidad poderosa, facilidad de uso y alto rendimiento?

### fork() System Call

La llamada al sistema fork() se utiliza para crear un nuevo proceso. Sin embargo, debes estar advertido: ciertamente es la rutina m치s extra침a que jam치s llamar치s. El proceso que se crea es una copia (casi) exacta del proceso que lo llam칩. Espec칤ficamente, aunque ahora tiene su propia copia del espacio de direcciones (es decir, su propia memoria privada), sus propios registros, su propio PC, etc. Cuando se crea el proceso hijo, ahora hay dos procesos activos en el sistema que nos importan: el padre y el hijo. Suponiendo que estamos ejecutando en un sistema con una sola CPU (por simplicidad), en ese punto podr칤a ejecutarse el hijo o el padre. El planificador de la CPU, un tema que discutiremos con gran detalle pronto, determina qu칠 proceso se ejecuta en un momento dado; dado que el planificador es complejo, generalmente no podemos hacer suposiciones fuertes sobre lo que elegir치 hacer, y por lo tanto, qu칠 proceso se ejecutar치 primero. Este no determinismo, como resulta, conduce a algunos problemas interesantes, particularmente en programas multihilo; por lo tanto, veremos mucho m치s no determinismo cuando estudiemos concurrencia en la segunda parte del libro.

### The wait() System Call

Hasta ahora, no hemos hecho mucho: solo crear un hijo que imprime un mensaje y sale. A veces, resulta bastante 칰til que un proceso padre espere a que un proceso hijo termine lo que est치 haciendo. Esta tarea se logra con la llamada al sistema wait() (o su versi칩n m치s completa waitpid()) En este ejemplo (p2.c), el proceso padre llama a wait() para retrasar su ejecuci칩n hasta que el hijo termine de ejecutarse. Cuando el hijo finaliza, wait() regresa el control al padre. Al agregar una llamada a wait() en el c칩digo anterior, la salida se vuelve determinista. Incluso cuando el padre se ejecuta primero, espera educadamente a que el hijo termine de ejecutarse, luego wait() regresa, y entonces el padre imprime su mensaje.

### exec() System Call

una 칰ltima y crucial pieza de la API de creaci칩n de procesos es la llamada al sistema exec(). Esta llamada al sistema es 칰til cuando quieres ejecutar un programa que es diferente al programa llamante. Por ejemplo, llamar a fork() solo es 칰til si deseas seguir ejecutando copias del mismo programa. Sin embargo, a menudo deseas ejecutar un programa diferente; exec()

```C
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf("hello (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) { // fork fall칩; salir
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // hijo (nuevo proceso)
        printf("child (pid:%d)\n", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup("wc"); // programa: "wc"
        myargs[1] = strdup("p3.c"); // argumento: archivo de entrada
        myargs[2] = NULL; // marcar el final del array
        execvp(myargs[0], myargs); // ejecuta word count
        printf("esto no deber칤a imprimirse");
    } else { // el padre sigue por este camino
        int rc_wait = wait(NULL);
        printf("parent of %d (rc_wait:%d) (pid:%d)\n", rc, rc_wait, (int) getpid());
    }
    return 0;
}
```

La llamada al sistema fork() es extra침a; su compa침ero en el crimen, exec(), tampoco es tan normal. Lo que hace: dado el nombre de un ejecutable (por ejemplo, wc), y algunos argumentos (por ejemplo, p3.c), carga el c칩digo (y datos est치ticos) de ese ejecutable y sobrescribe su segmento de c칩digo actual (y datos est치ticos actuales) con 칠l; el heap, la pila y otras partes del espacio de memoria del programa se re-inicializan. Luego, el sistema operativo simplemente ejecuta ese programa, pasando cualquier argumento como el argv de ese proceso. As칤, no crea un nuevo proceso; m치s bien, transforma el programa que se est치 ejecutando (anteriormente p3) en un programa diferente (wc). Despu칠s de exec() en el hijo, es casi como si p3.c nunca se hubiera ejecutado; una llamada exitosa a exec() nunca regresa.

### 쯇or qu칠? Motivando a la API

Por supuesto, una gran pregunta que podr칤as tener es: 쯣or qu칠 construir una interfaz tan extra침a para lo que deber칤a ser el acto simple de crear un nuevo proceso? Bueno, resulta que la separaci칩n de fork() y exec() es esencial para construir un shell en UNIX, porque permite que el shell ejecute c칩digo despu칠s de la llamada a fork() pero antes de la llamada a exec(). Este c칩digo puede alterar el entorno del programa que est치 a punto de ejecutarse, lo que permite construir f치cilmente una variedad de caracter칤sticas interesantes.

El shell es solo un programa de usuario. Te muestra un prompt y luego espera que escribas algo en 칠l. Luego escribes un comando (es decir, el nombre de un programa ejecutable, m치s cualquier argumento); en la mayor칤a de los casos, el shell averigua d칩nde se encuentra el ejecutable en el sistema de archivos, llama a fork() para crear un nuevo proceso hijo que ejecute el comando, llama a alguna variante de exec() para ejecutar el comando, y luego espera a que el comando termine llamando a wait(). Cuando el hijo termina, el shell regresa de wait() y vuelve a imprimir un prompt, listo para tu pr칩ximo comando.

La separaci칩n de fork() y exec() permite al shell hacer un mont칩n de cosas 칰tiles con relativa facilidad. Por ejemplo:

```shell
wc p3.c > newfile.txt
```

En el ejemplo anterior, la salida del programa wc se redirige al archivo de salida newfile.txt (el signo mayor que indica dicha redirecci칩n). La forma en que el shell logra esta tarea es bastante simple: cuando se crea el hijo, antes de llamar a exec(), el shell (espec칤ficamente, el c칩digo ejecutado en el proceso hijo) cierra la salida est치ndar y abre el archivo newfile.txt. Al hacer esto, cualquier salida del programa que est치 a punto de ejecutarse, wc, se env칤a al archivo en lugar de a la pantalla (los descriptores de archivos abiertos se mantienen abiertos a trav칠s de la llamada a exec(), lo que permite este comportamiento).

La Figura 5.4 muestra un programa que hace exactamente esto. La raz칩n por la que esta redirecci칩n funciona se debe a una suposici칩n sobre c칩mo el sistema operativo gestiona los descriptores de archivos. Espec칤ficamente, los sistemas UNIX comienzan a buscar descriptores de archivos libres desde cero. En este caso, STDOUT_FILENO ser치 el primero disponible y, por lo tanto, se asignar치 cuando se llame a open(). Las escrituras subsecuentes del proceso hijo al descriptor de archivo de salida est치ndar, por ejemplo, mediante rutinas como printf(), se dirigir치n autom치ticamente al archivo reci칠n abierto en lugar de a la pantalla.

Notar치s (al menos) dos detalles interesantes sobre esta salida. Primero, cuando se ejecuta p4, parece que no ha sucedido nada; el shell simplemente imprime el prompt de comando y est치 inmediatamente listo para tu pr칩ximo comando. Sin embargo, ese no es el caso; el programa p4 realmente llam칩 a fork() para crear un nuevo hijo y luego ejecut칩 el programa wc mediante una llamada a execvp(). No ves ninguna salida en la pantalla porque se ha redirigido al archivo p4.output. Segundo, puedes ver que cuando usamos cat para ver el archivo de salida, se encuentra toda la salida esperada de la ejecuci칩n de wc.

Por ahora, basta con decir que la combinaci칩n de fork()/exec() es una manera poderosa de crear y manipular procesos.

### Process Control and Users

M치s all치 de fork(), exec() y wait(), existen muchas otras interfaces para interactuar con procesos en sistemas UNIX. Por ejemplo, la llamada al sistema kill() se utiliza para enviar se침ales a un proceso, incluyendo directivas para pausar, finalizar, y otras 칩rdenes 칰tiles. Para mayor comodidad, en la mayor칤a de los shells de UNIX, ciertas combinaciones de teclas est치n configuradas para enviar una se침al espec칤fica al proceso que se est치 ejecutando; por ejemplo, control-c env칤a un SIGINT (interrupci칩n) al proceso (normalmente termin치ndolo), y control-z env칤a una se침al SIGTSTP (stop), pausando as칤 el proceso en mitad de su ejecuci칩n (puedes reanudarlo m치s tarde con un comando, por ejemplo, el comando fg que se encuentra en muchos shells). Todo el subsistema de se침ales proporciona una infraestructura rica para entregar eventos externos a procesos, incluyendo formas de recibir y procesar esas se침ales dentro de procesos individuales, as칤 como formas de enviar se침ales a procesos individuales o a grupos enteros de procesos.

Para utilizar esta forma de comunicaci칩n, un proceso debe usar la llamada al sistema signal() para "capturar" varias se침ales; al hacerlo, se asegura de que cuando una se침al particular se entregue a un proceso, este suspender치 su ejecuci칩n normal y ejecutar치 una porci칩n espec칤fica de c칩digo en respuesta a la se침al. Puedes leer en otra parte [SR05] para aprender m치s sobre las se침ales y sus m칰ltiples complejidades.

Esto naturalmente plantea la pregunta: 쯤ui칠n puede enviar una se침al a un proceso y qui칠n no? Generalmente, los sistemas que usamos pueden ser utilizados por m칰ltiples personas al mismo tiempo; si una de estas personas pudiera enviar arbitrariamente se침ales como SIGINT (para interrumpir un proceso, probablemente termin치ndolo), la usabilidad y seguridad del sistema se ver칤an comprometidas. Como resultado, los sistemas modernos incluyen una concepci칩n s칩lida de la noci칩n de un usuario.

- El usuario, despu칠s de ingresar una contrase침a para establecer credenciales, inicia sesi칩n para obtener acceso a los recursos del sistema.
- El usuario puede entonces lanzar uno o muchos procesos y ejercer control total sobre ellos (pausarlos, matarlos, etc.).
- Los usuarios generalmente solo pueden controlar sus propios procesos; es el trabajo del sistema operativo distribuir los recursos (como CPU, memoria y disco) a cada usuario (y sus procesos) para cumplir con los objetivos generales del sistema.

### Herramientas 칰tiles

Existen muchas herramientas de l칤nea de comandos que tambi칠n son 칰tiles. Por ejemplo, el comando ps te permite ver qu칠 procesos est치n en ejecuci칩n; consulta las p치ginas de manual para obtener algunas banderas 칰tiles que puedes pasar a ps. La herramienta top tambi칠n es bastante 칰til, ya que muestra los procesos del sistema y cu치ntos recursos de CPU y otros est치n consumiendo. Curiosamente, muchas veces cuando ejecutas top, este afirma ser el que m치s recursos consume; quiz치s es un poco egoc칠ntrico. El comando kill se puede usar para enviar se침ales arbitrarias a los procesos, al igual que el comando killall, que es un poco m치s amigable para el usuario. Aseg칰rate de usarlos con cuidado; si accidentalmente matas tu gestor de ventanas, la computadora frente a ti puede volverse bastante dif칤cil de usar.

Finalmente, hay muchos tipos diferentes de medidores de CPU que puedes usar para obtener una comprensi칩n r치pida de la carga en tu sistema; por ejemplo, siempre mantenemos MenuMeters (de Raging Menace Software) funcionando en nuestras barras de herramientas de Macintosh, para que podamos ver cu치nto CPU se est치 utilizando en cualquier momento. En general, cuanta m치s informaci칩n tengas sobre lo que est치 sucediendo, mejor.

### Aside: El superusuario (ROOT)

Un sistema generalmente necesita un usuario que pueda administrar el sistema y que no est칠 limitado de la misma manera que la mayor칤a de los usuarios. Dicho usuario deber칤a poder matar un proceso arbitrario (por ejemplo, si est치 abusando del sistema de alguna manera), aunque ese proceso no haya sido iniciado por este usuario. Tal usuario tambi칠n deber칤a poder ejecutar comandos poderosos como shutdown (que, como es de esperarse, apaga el sistema). En los sistemas basados en UNIX, estas habilidades especiales se otorgan al superusuario (a veces llamado root). Mientras que la mayor칤a de los usuarios no pueden matar los procesos de otros usuarios, el superusuario s칤 puede. Ser root es como ser Spider-Man: con un gran poder viene una gran responsabilidad. Por lo tanto, para aumentar la seguridad (y evitar errores costosos), generalmente es mejor ser un usuario regular; si necesitas ser root, procede con cautela, ya que todos los poderes destructivos del mundo de la computaci칩n est치n ahora a tu alcance.

## Ejecuci칩n Directa Limitada

### Problema #1: Operaciones restringidas

> **El crux del problema**: Un proceso debe poder realizar E/S y otras operaciones restringidas, pero sin darle al proceso un completo control sobre el sistema. 쮺omo pueden el SO y el hardware trabajar juntos para lograrlo?

Un enfoque ser 패캼a simplemente dejar que cualquier proceso haga lo que quiera en terminos de E/S y otras operaciones relacionadas. Sin embargo, hacerlo evitar칤a la construccion de muchos tipos de sistemas que son deseables. Por ejemplo, si deseamos construir un sistema de archivos que verifique los permisos antes de otorgar acceso a un archivo, no podemos simplemente permitir que cualquier usuario emita E/Ss al disco; si lo hicieramos, un proceso podr칤a simplemente leer o escribir el disco entero y as칤 todas las protecciones se perder칤an.

Modos de procesadores:

- **Modo Kernel**: Modo en el que el SO corre. El codigo que corre puede hacer lo que quiera, incluyendo operaciones privilegiadas tales como emitir solicitudes E/S y ejecutar todo tipo de instrucciones restringidas.
- **Modo usuario**: el codigo que corre en modo usuario esta restringido en lo que puede hacer.

**쯈u칠 debe hacer un proceso de usuario cuando quiera realizar una operacion privilegiada, como leer del disco?** Para permitir esto, practicamente todo el hardware moderno les proporciona a los programas de usuario la capacidad de que realicen una **syscall**.

Para ejecutar una syscall, un programa debe ejecutar una instrucci칩n **trap** especial. Esta instruccion simult치neamente salta al kernel y eleva el nivel de privilegios; una vez en el kernel, el sistema ahora puede realizar cualquier operacion privilegiada que sea necesaria (si esta permitida), y as칤 hacer el trabajo requerido para el proceso de llamada. Cuando finaliza, el SO llama a una instrucci칩n especial de **retorno de la trap** que, como era de esperar, vuelve al programa de usuario que realiza la llamada y, al mismo tiempo, reduce el nivel de privilegios al de modo usuario.

El Hardware debe tener un poco de cuidado al ejecutar una trap, ya que debe asegurarse de guardar suficientes registros del programa que hizo la llamada para poder regresar correctamente cuando el sistema operativo emita la instrucci칩n del retorno a la trap.

> **Detalle de suma importancia**: 쮺omo sabe la trap que c칩digo ejecutar dentro del SO? Claramente, el proceso que realiza la llamada no puede especificar una direccion a la que saltar (como lo har캼a al realizar una llamada de procedimiento); hacerlo permitir칤a a los programas saltar a cualquier parte del kernel, lo que claramente es una Muy Mala Idea. Por lo tanto, el kernel debe controlar cuidadosamente que c칩digo se ejecuta en una instruccion trap. 패

El kernel lo hace configurando una **tabla de traps** en el momento de booteo. Cuando la maquina arranca, lo hace en modo privilegiado (kernel) y, por lo tanto, es libre de configurar el hardware de la maquina seg칰n sea necesario. Una de las primeras cosas que hace el SO es decirle al hardware que c칩digo debe ejecutar cuando ocurren ciertos eventos excepcionales. Por ejemplo, 쯤ue codigo debe ejecutarse cuando se produce una interrupcion del disco duro, cuando se produce una interrupcion del teclado o cuando un programa realiza una llamada al sistema? El sistema operativo informa al hardware de la ubicacion de estos gestores de traps, generalmente con algun 패tipo de instruccion especial. Una vez que se informa al hardware, recuerda la ubicacion de estas rutinas, hasta que se reinicia la m치quina y, por lo tanto, el hardware sabe que hacer (es decir, a que c칩digo saltar) cuando tienen lugar las llamadas del sistema y otros eventos excepcionales.

Para especificar la syscall exacta, en general se asigna un **n칰mero de syscall a cada syscall**. Por lo tanto, el codigo de usuario es responsable de colocar el n칰mero de llamada al sistema deseado en un registro o en una ubicacion espec칤fica en el stack; el SO, al encargarse de la llamada al sistema dentro del controlador de traps, examina este n칰mero, asegura que es valido y, si lo es, ejecuta el c칩digo correspondiente. Este nivel de indireccion sirve como una forma de protecci칩n; el c칩digo de usuario no puede especificar una direccion exacta a la que saltar, sino que debe solicitar un servicio en particular a traves de un n칰mero.

Un ultimo tema aparte: poder ejecutar la instrucci칩n para decirle al hardware donde estan las tablas de traps es una capacidad muy poderosa. Por lo tanto, como habras adivinado, tambi칠n es una operacion 패privilegiada.

Hay dos fases en el protocolo de ejecucion directa limitada (LDE). En el primero (en el momento de boot), el kernel inicializa la tabla de traps y la CPU recuerda su ubicacion para su uso futuro. El kernel lo hace mediante una instruccion privilegiada.

En el segundo (cuando se ejecuta un proceso), antes de usar una instruccion de retorno de la trap para iniciar la ejecucion del proceso, el kernel configura algunas cosas (por ejemplo, asigna un nodo en la lista de procesos, asigna memoria); luego cambia la CPU a modo usuario y comienza a ejecutar el proceso. Cuando el proceso desea emitir una llamada al sistema, vuelve a entrar en el SO, que se encarga y una vez mas devuelve el control al proceso a traves de un retorno de la trap. El proceso luego completa su trabajo y retorna de main(); esto generalmente retornara a algun c칩digo auxiliar que saldr치 correctamente del programa (por ejemplo, con la llamada al sistema exit(), que trapea al SO). En este punto, el sistema operativo se limpia y hemos terminado.

### Problema #2: Cambio de procesos

El siguiente problema con la ejecucion directa es lograr un intercambio de procesos. Intercambiar procesos deber칤a ser simple, 쯨erdad? El SO deber 패캼a decidir detener un proceso e iniciar otro. 쮺ual es el problema? En realidad, es un poco complicado: espec칤ficamente, si un proceso se esta ejecutando en la CPU, por definici칩n, significa que el SO no esta corriendo. Si el SO no se est치 ejecutando, 쯖칩mo puede hacer algo? (pista: no puede). Si bien esto suena casi filosofico, es un problema real: claramente no hay forma de que el SO tome una accion si no se est치 ejecutando en la CPU. Llegamos as칤 a nuestro problema.

> La cuesti칩n: C칩mo recuperar el control el control de la CPU: 쮺칩mo puede el sistema operativo **recuperar el control** de la CPU para que pueda cambiar entre procesos?

#### Un enfoque cooperativo: Esperar las llamadas al sistema.

Un enfoque que han adoptado algunos sistemas en el pasado (por ejemplo, las primeras versiones del SO de Macintosh o el antiguo sistema Xerox Alto) se conoce como el enfoque cooperativo. En este estilo, el SO conf칤a en que los procesos del sistema se comporten de manera razonable. Se supone que los procesos que se ejecutan durante demasiado tiempo ceden periodicamente la CPU para que el SO pueda decidir ejecutar alguna otra tarea. As칤, podr칤as preguntarte, 쯖omo un proceso amigable cede la CPU en este mundo utopico? La mayor칤a de los procesos, transfieren el control de la CPU al SO con bastante frecuencia haciendo llamadas al sistema, por ejemplo, para abrir un archivo y luego leerlo, o para enviar un mensaje a otra m치quina, o para crear un nuevo proceso.

Los sistemas como este a menudo incluyen una llamada al sistema expl칤cita **yield**, que no hace nada mas que transferir el control al sistema operativo para que pueda ejecutar otros procesos. Las aplicaciones tambien transfieren el control al SO cuando hacen algo ilegal. Por ejemplo, si una aplicacion se divide por cero o intenta acceder a la memoria a la que no deber칤a poder acceder, generara una trap al SO. El cual volvera a tener el control de la CPU (y probablemente terminara el proceso infractor). Por lo tanto, en un sistema de programacion cooperativo, el SO recupera el control de la CPU esperando una llamada del sistema o una operacion ilegal de algun tipo. Tambi칠n podr칤as estar pensando: **쯅o es este enfoque pasivo menos que ideal? 쯈ue sucede, por ejemplo, si un proceso (ya sea malicioso o simplemente lleno de errores) termina en un bucle infinito y nunca realiza una llamada al sistema? 쯈ue puede hacer ah칤 el SO?**

#### Un enfoque no Cooperativo: El SO toma el control.

Sin alguna ayuda adicional del hardware, resulta que el SO no puede hacer mucho cuando un proceso se niega a realizar llamadas al sistema (o errores) y as칤, devolver el control al SO. De hecho, en el enfoque cooperativo, su unico recurso cuando un proceso se atasca en un bucle infinito es recurrir a la antigua solucion para todos los problemas en los sistemas informaticos: reiniciar la m치quina. Por lo tanto, llegamos nuevamente a un subproblema de nuestra busqueda general para obtener el control de la CPU.

> 쮺omo puede el SO obtener el control de la CPU incluso si los procesos no son cooperativos? 쯈ue puede hacer el SO para garantizar que un proceso fraudulento no se apodere de la maquina?

La respuesta es simple y fue descubierta por varias personas que constru칤an sistemas inform치ticos hace muchos a침os: una interrupci칩n por tiempo. Se puede programar un dispositivo temporizador para generar una interrupci칩n cada ciertos milisegundos; cuando se genera la interrupci칩n, el proceso que se est치 ejecutando actualmente se detiene y se ejecuta un gestor de interrupciones preconfigurado en el sistema operativo (SO). En este punto, el SO recupera el control de la CPU y, por lo tanto, puede hacer lo que le plazca: detener el proceso actual e iniciar uno diferente.

Como comentamos anteriormente con las llamadas al sistema, el SO debe informar al hardware qu칠 c칩digo ejecutar cuando se produce la interrupci칩n por tiempo; por lo tanto, en el momento del arranque (boot), el SO hace exactamente eso. Adem치s, durante la secuencia de arranque, el sistema operativo debe iniciar el temporizador, lo cual es una operaci칩n privilegiada. Una vez que el temporizador ha comenzado, el SO puede estar seguro de que el control finalmente le ser치 devuelto, y, por lo tanto, es libre de ejecutar programas de usuario. El temporizador tambi칠n se puede apagar (otra operaci칩n privilegiada), algo que discutiremos m치s adelante cuando entendamos la concurrencia en mayor detalle.

> Tip: Lidiar con la mala conducta de aplicaciones: Los sistemas operativos a menudo tienen que lidiar con procesos que se comportan mal, ya sea por dise침o (malicia) o por accidente (errores), que intentan hacer algo que no deber칤an. En los sistemas modernos, la forma en que el SO maneja tal mala conducta es simplemente terminar al infractor. 춰Un strike y est치s fuera! Quiz치s sea brutal, pero 쯤u칠 m치s deber칤a hacer el SO cuando un proceso intenta acceder a memoria ilegalmente o ejecutar una instrucci칩n ilegal?

Aqu칤 tienes el texto ajustado:

Es importante notar que el hardware tiene cierta responsabilidad cuando ocurre una interrupci칩n, en particular para guardar suficiente informaci칩n del estado del programa que se estaba ejecutando cuando ocurri칩 la interrupci칩n, de modo que una instrucci칩n posterior de retorno de la trap pueda reanudar el programa en ejecuci칩n correctamente. Este conjunto de acciones es bastante similar al comportamiento del hardware durante una trap por llamada al sistema expl칤cita en el kernel, donde varios registros se guardan (por ejemplo, en un stack del kernel) y, por lo tanto, se restauran f치cilmente mediante la instrucci칩n de retorno de la trap.

### Guardar y restaurar contexto

Ahora que el SO ha recuperado el control, ya sea de forma cooperativa a trav칠s de una llamada al sistema o de manera m치s forzada a trav칠s de una interrupci칩n por tiempo, se debe tomar una decisi칩n: continuar ejecutando el proceso actual o cambiar a uno diferente. Esta decisi칩n la toma una parte del sistema operativo conocida como planificador; discutiremos las pol칤ticas de planificaci칩n con mayor detalle en los pr칩ximos cap칤tulos.

Si se decide cambiar de proceso, el SO ejecuta un fragmento de c칩digo de bajo nivel llamado cambio de contexto. Un cambio de contexto es conceptualmente simple: el SO debe guardar algunos valores de los registros del proceso que se est치 ejecutando actualmente (en su stack de kernel, por ejemplo) y restaurar los valores correspondientes para el proceso que va a ejecutarse a continuaci칩n (desde su stack de kernel). De este modo, el SO garantiza que cuando finalmente cuando se ejecute la instrucci칩n de retorno de la trap, en lugar de regresar al proceso que se estaba ejecutando, el sistema reanudar치 la ejecuci칩n de otro proceso.

Para guardar el contexto del proceso que se est치 ejecutando actualmente, el SO ejecutar치 c칩digo assembly de bajo nivel para almacenar los registros de prop칩sito general, el contador de programa (PC) y el puntero del stack de kernel del proceso actual. Luego, restaurar치 esos registros, el PC, y cambiar치 al stack de kernel del proceso que se va a ejecutar a continuaci칩n. Al cambiar de stack, el kernel entra en la llamada al c칩digo de cambio de contexto en el contexto de un proceso (el que fue interrumpido) y regresa en el contexto de otro (el que pronto se ejecutar치). Cuando el SO finalmente ejecuta una instrucci칩n de retorno de la trap, el proceso que estaba por ejecutarse se convierte en el proceso que se est치 ejecutando en ese momento. As칤 se completa el cambio de contexto.

> Tip: Sumar una interrupcion por tiempo le da al SO la capacidad de ejecutarse nuevamente en una CPU incluso si los procesos actuan de manera no cooperativa. Por lo tanto, esta caracter 패캼stica de hardware es esencial para ayudar al SO a mantener el control de la maquina.

**Ver ejemplo**:

Aqu칤 tienes el texto ajustado:

En este ejemplo, el proceso A se est치 ejecutando y luego es interrumpido por el temporizador. El hardware guarda sus registros (en su stack de kernel) y entra en el kernel (cambiando a modo kernel). En el gestor de interrupciones del temporizador, el SO decide cambiar de ejecutar el Proceso A al Proceso B. En ese punto, llama a la rutina switch(), que guarda cuidadosamente los valores de los registros actuales (en la estructura del proceso de A), restaura los registros del Proceso B (desde su entrada en la estructura de proceso) y luego realiza el cambio de contexto, espec칤ficamente cambiando el puntero del stack para utilizar el stack de kernel de B (y no el de A). Finalmente, el SO retorna de la trap, lo que restaura los registros de B y comienza a ejecutarlo.

Es importante notar que hay dos tipos de guardado y restauraci칩n de registros que ocurren durante este protocolo. El primero es cuando ocurre la interrupci칩n por tiempo; en este caso, los registros de usuario del proceso en ejecuci칩n son guardados impl칤citamente por el hardware, utilizando el stack de kernel de ese proceso. El segundo es cuando el SO decide cambiar de A a B; en este caso, los registros del kernel son guardados expl칤citamente por el software (es decir, el SO), pero esta vez en la memoria dentro de la estructura del proceso. La 칰ltima acci칩n hace que el sistema funcione como si reci칠n hubiera trapeado al kernel desde B, y no desde A.

Para darte una mejor idea de c칩mo se realiza dicho cambio, la Figura 6.4 muestra el c칩digo de cambio de contexto de xv6. Trata de encontrarle sentido (tendr치s que saber un poco de x86, as칤 como algo de xv6). Las estructuras del contexto "old" y "new" se encuentran en las estructuras del proceso antiguo y nuevo, respectivamente.

> Tip: Reiniciar es 칰til: Anteriormente, notamos que la 칰nica soluci칩n para los bucles infinitos (y comportamientos similares) bajo la preferencia cooperativa es reiniciar la m치quina. Aunque uno podr칤a burlarse de este truco, investigadores/as han demostrado que reiniciar (o en general, comenzar de nuevo con alg칰n software) puede ser una herramienta muy 칰til para construir sistemas robustos. Espec칤ficamente, el reinicio es 칰til porque devuelve el software a un estado conocido y probablemente m치s testeado. Los reinicios tambi칠n recuperan recursos deteriorados o perdidos (por ejemplo, memoria) que de otro modo podr칤an ser dif칤ciles de manejar. Finalmente, los reinicios son f치ciles de automatizar. Por todas estas razones, no es raro en los servicios de Internet de cl칰steres a gran escala que el software de administraci칩n del sistema reinicie peri칩dicamente conjuntos de m치quinas para restablecerlas y as칤 obtener las ventajas mencionadas anteriormente. Por lo tanto, la pr칩xima vez que reinicies, no estar치s simplemente realizando un truco superficial. M치s bien, estar치s utilizando un enfoque probado para mejorar el comportamiento de un sistema inform치tico. 춰Bien hecho!

### 쯊e preocupa la concurrencia?

Algunos/as de ustedes, como lectores/as atentos/as y reflexivos/as, pueden estar pensando ahora: "Hmm... 쯤u칠 pasa cuando, durante una llamada al sistema, ocurre una interrupci칩n del temporizador?" o "쯈u칠 pasa cuando manejas una interrupci칩n y ocurre otra? 쯅o se vuelve dif칤cil de manejar en el kernel?" Buenas preguntas, 춰todav칤a hay esperanzas en vos!

La respuesta es s칤, el SO debe preocuparse por lo que sucede si, durante la interrupci칩n o el manejo de traps, se produce otra interrupci칩n. Este, de hecho, es exactamente el tema de toda la segunda parte de este libro, sobre concurrencia; aplazaremos una discusi칩n detallada hasta entonces.

Para despertar tu apetito, esbozaremos algunos conceptos b치sicos de c칩mo el SO maneja estas situaciones complicadas. Una cosa simple que puede hacer un SO es deshabilitar las interrupciones durante el manejo de interrupciones; al hacerlo, se asegura de que, mientras se procesa una interrupci칩n, no llegue otra a la CPU. Por supuesto, el SO debe tener cuidado al hacerlo; deshabilitar las interrupciones durante demasiado tiempo podr칤a provocar la p칠rdida de interrupciones, lo cual es (en t칠rminos t칠cnicos) malo.

Los sistemas operativos tambi칠n han desarrollado una serie de esquemas de bloqueo sofisticados para proteger el acceso simult치neo a las estructuras de datos internas. Esto permite que se realicen m칰ltiples actividades dentro del kernel al mismo tiempo, lo cual es particularmente 칰til en multiprocesadores. Sin embargo, como veremos en la pr칩xima parte de este libro sobre concurrencia, dicho bloqueo puede ser complicado y dar lugar a una variedad de errores interesantes y dif칤ciles de encontrar.

> Aparte: T칠rminos clave de virtualizaci칩n de la CPU (Mecanismos)

> La CPU debe admitir al menos dos modos de ejecucion: un modo usuario restringido y un modo kernel privilegiado (no restringido).

> Las aplicaciones de usuario t 패캼picas se ejecutan en modo de usuario y utilizan una llamada al sistema para trapear al kernel y solicitar servicios del sistema operativo.

> La instrucci칩n trap guarda cuidadosamente el estado del registro, cambia el estado del hardware al modo kernel y salta al sistema operativo a un destinopreestablecido: la **tabla de traps**.

> Cuando el SO termina de dar servicio a una llamada al sistema, regresa al programa de usuario a traves de otra instrucci칍n especial de retorno de la trap, que reduce el privilegio y devuelve el control a la instruccion despu칠s de la trampa que salt칩 al sistema operativo.

> EL SO debe configurar las tablas de traps en el momento del booteo y asegurarse de que los programas de usuario no puedan modificarlas f치cilmente. Todo esto es parte del protocolo de **ejecuci칩n directa limitada** que ejecuta programas de manera eficiente pero sin perder control del SO.

> Una vez que un programa se est치 ejecutando, el SO debe utilizar mecanismos de hardware para garantizar que el programa de usuario no se ejecute para siempre, es decir, la **interrupci칩n por temporizador**. Este es un enfoque **no-cooperativo** para la planificaci칩n del CPU.

> A veces, el SO durante una interrupci칩n del temporizador o una syscall, puede desear cambiar de ejecutar el proceso actual a uno diferente, una t칠cnica de bajo nivel conocida como **cambio de contexto**.

## Planificaci칩n de la CPU

> La cuesti칩n: C칩mo desarrollar una pol칤tica de planificaci칩n. 쮺칩mo deber칤amos desarrollar un marco b치sico para pensar en las pol칤ticas de planificaci칩n? 쮺u치les son las suposiciones clave? 쯈ue m칠tricas son importantes? 쯈ue enfoques b치sicos se utilizaron en los primeros sistemas inform치ticos?

### Suposiciones sobre la carga del trabajo

- Suposiciones simplificadoras sobre los procesos que se ejecutan en el sistema, **carga de trabajo**.
  - Determinar la carga de trabajo es una parte fundamental de la creaci칩n de pol칤ticas, y cuando m치s se sepa sobre la carga de trabajo, m치s afinada podr치 ser la pol칤tica.
- **pausa dram치tica**: una disciplina de planificaci칩n completamente funcional. (disiplina tambi칠n conocida como pol칤ticas de planificaci칩n)
- Los procesos a estas alturas del libro son llamados **trabajos**.

### M칠tricas de planificaci칩n

Nos permitir치n comparar diferentes pol칤ticas de planificaci칩n. Una m칠trica es algo que usamos para medir algo y hay varias m칠tricas diferentes que tienen sentido en el mundo de la planificaci칩n.

- Tiempo de entrega
  $
  T*{entrega} = T*{finalizaci칩n} - T\_{llegada}
  $

  El tiempo de entrega es una m칠trica de rendimiento.

- Justicia
  Se mide con el 칈ndice de Justicia de Jain.

Un scheduler suelen estar en desacuerdo en la planificaci칩n. Un planificador puede optimizar el rendimiento, pero a costa de evitar que se ejecuten algunos trabajos, reduciendo as칤 la justicia.

#### FIFO

- Primero en llegar, primero en ser atendido (FCFS, First Come First Served).
- Es simple y f치cil de implementar.
- Los trabajos con diferentes longitudes pueden ocacionar problemas (Efecto de convoy), una serie de consumidores potenciales de alg칰n recurso, relativamente cortos, se ponen en cola detr치s de un consumidor de gran peso.

> Tip: El principio de SJF.
> La idea de SJF representa un principio de planificaci칩n general que se puede aplicar a cuaquier sistema en el que el tiempo de entrega percibido por el cliente (o, en nuestro caso, trabajo) sea importante. Pens치 en cualquier fila en la que hayas esperado: si el estableciemiento en cuesti칩n se preocupa por la satisfacci칩n del cliente, es probable que haya tenido en cuenta SJF. Por ejemplo, los supermercados suelen tener una l칤nea de "diez art칤culos o menos" para garantizar que los compradores que s칩lo tienen unas pocas cosas para comprar no se queden atrapados detr치s de la familia que se prepara para el pr칩ximo invierno nuclear.

#### Trabajo m치s corto primero (SJF)

- Shortest Job First.
- Es una pol칤tica que ejecuta primero el trabajo m치s corto, luego el siguiente m치s corto y as칤 sucesivamente.
- SJF es un algoritmo de planificaci칩n 칩ptimo, pero sigue teniendo el problema del convoy si es que llega un trabajo pesado y durante de la ejecuci칩n de este llega uno m치s corto.

#### Trabajo de menor tiempo restante primero (STCF)

- Shortest Time-to-Completion First o tambi칠n conocido como Trabajo m치s corto primero con apropiaci칩n.
- Cada vez que un nuevo trabajo ingresa al sistema, el planificador STCF determina a cu치l de los trabajos restantes (incluyendo al nuevo trabajo)le queda el menor tiempo hasta finalizar, y lo elige para ser ejecutado.
- STCF es demostrablemente 칩ptimo.

#### El tiempo de respuesta

- Si supieramos cuanto tiempo durar칤a un trabajo y si los trabajos usaran solamente la CPU, y adem치s nuestra 칰nica m칠trica fuera el tiempo de entrega, STCF ser칤a una excelente pol칤tica de planificaci칩n. Para varios de los primeros sistemas inform치ticos por lotes, estos tipos de algoritmos de planificaci칩n ten칤an cierto sentido, sin embargo, todo cambi칩 cuando se introdujeron las m치quinas de tiempo compartido.

- Definimos el tiempo de respuesta como el tiempo desde que el trabajo llega a un sistema hasta la primera vez que es elegido para ser ejecutado.

$ T*{respuesta} = T*{1ra-ejecuci칩n} - T\_{llegada}$

- Si bien esta m칠trica es bastante buena para el tiempo de entrega, pero es bastante malo para el tiempo de respuesta e interactividad.

#### Round Robin

- En lugar de ejecutar trabajos hasta su finalizaci칩n, RR ejecuta cada trabajo durante un **segmento de tiempo** (A veces llamado **quantum de planificaci칩n**) y luego cambia al siguiente trabajo en la cola de ejecuci칩n. Esto lo hace repetidas veces hasta que se terminan todos los trabajos.
- A veces RR se denomina como **divisi칩n de tiempo**.
- Notar que la duraci칩n de un segmento de tiempo debe ser un m칰ltiplpo del per칤odo de interrupci칩n del temporizador, por lo tanto si el temporizador se interrumpe cada 1' milisegundos,s el segmento de tiempo pord칤a ser de 10, 20 o cualquier otro m칰ltiplo de 10ms.

- Cuanto m치s corto sea la duraci칩n del segmento de tiempo, mejor ser치 el rendimiento de RR, seg칰n la m칠trica del tiempo de respuesta. Sin embargo, si el segmento de tiempo es demasiado corto, puede resultar problem치tico ya que el costo del cambio de contexto dominar칤a el rendimiento en general.
- Por ende decidir la duraci칩n del segmento de tiempo presenta un intercambio que el dise침ador del sistema debe estar dispuesto a hacer; tiene que ser lo suficientemente largo como para amortizar el costo del cambio, pero no tan largo como para que el sistema deje de ser responsivo.

- RR es, de hecho, una de las peores pol칤ticas si nuestra m칠trica es el tiempo de entrega. Intuitivamente, esto tiene sentido: lo que hace RR es estirar cada trabajo tanto como pueda, ejecutando cada trabajo por muy poco tiempo antes de pasar al siguiente. Debido a que el tiempo de entrega solo se preocupa por cu치ndo terminan los trabajos, RR es casi pesimista, incluso peor que el simple FIFO en muchos casos.

- Generalmente, cualquier pol칤tica (como RR) que sea justa, es decir, que divida uniformemente la CPU entre los procesos activos en una escala de tiempo peque침a, tendr칤a un desempe침o deficiente en m칠tricas como el tiempo de entrega.

### Incorportando E/S

Claramente, el planificador tiene que tomar una decisi칩n cuando alg칰n trabajo inicia una solicitud de E/S, ya que el trabajo que se est치 ejecutando deja de usar la CPU durante la E/S y se queda bloqueado esperando su finalizaci칩n. Si la E/S se env칤a a una unidad de disco duro, es posible que el proceso se bloquee durante unos milisegundos o m치s, dependiendo de la carga de E/S de la unidad en ese momento. Por lo tanto, quiz치s sea mejor que el planificador aproveche este tiempo para ejecutar otro trabajo en la CPU.

El planificador tambi칠n debe tomar una decisi칩n cuando se termina la E/S. Cuando esto ocurre, se genera una interrupci칩n y se ejecuta el SO, moviendo el proceso que emiti칩 la E/S del estado bloqueado al estado listo.

![alt text](imgs/image1.png)

# Virtualizaci칩n de la memoria

En los primeros d칤as, construir sistemas inform치ticos era f치cil. 쯇or qu칠, preguntas? Porque los usuarios no esperaban mucho. Son esos malditos usuarios con sus expectativas de 랁acilidad de uso, 라lto rendimiento, 랁iabilidad, etc., los que realmente han causado todos estos dolores de cabeza. La pr칩xima vez que te encuentres con uno de esos usuarios de computadoras, agrad칠celes por todos los problemas que han causado.

## Sistemas Tempranos

Desde la perspectiva de la memoria, las primeras m치quinas no proporcionaban mucha abstracci칩n a los usuarios.El sistema operativo era un conjunto de rutinas (una biblioteca, en realidad) que resid칤a en la memoria (comenzando en la direcci칩n f칤sica 0 en este ejemplo), y hab칤a un 칰nico programa en ejecuci칩n (un proceso) que resid칤a en la memoria f칤sica (comenzando en la direcci칩n f칤sica 64k en este ejemplo) y usaba el resto de la memoria. Hab칤a pocas ilusiones aqu칤, y el usuario no esperaba mucho del sistema operativo.

![alt text](imgs/image_3.png)

## Multiprogramaci칩n y Tiempo compartido

Despu칠s de un tiempo, dado que las m치quinas eran costosas, la gente comenz칩 a compartirlas de manera m치s efectiva. As칤 naci칩 la era de la multiprogramaci칩n, en la cual m칰ltiples procesos estaban listos para ejecutarse en un momento dado, y el sistema operativo cambiaba entre ellos.

Pronto, sin embargo, la gente comenz칩 a exigir m치s de las m치quinas, y naci칩 la era del tiempo compartido. Espec칤ficamente, muchos se dieron cuenta de las limitaciones de la computaci칩n por lotes, particularmente para los propios programadores, quienes estaban cansados de largos (y por lo tanto ineficaces) ciclos de depuraci칩n de programas.

- Una forma de implementar el tiempo compartido ser칤a ejecutar un proceso por un corto tiempo, d치ndole acceso total a toda la memoria, luego detenerlo, guardar todo su estado en alg칰n tipo de disco (incluyendo toda la memoria f칤sica), cargar el estado de otro proceso, ejecutarlo por un tiempo, y as칤 implementar una especie de compartici칩n cruda de la m치quina. Este enfoque tiene un problema: **Es demasiado lento** a medida que la memoria crece.

- Por otro lado, dejar los procesos en la memoria mientras cambiamos entre ellos, permitiendo que el sistema operativo implemente el tiempo compartido de manera eficiente es lo que preferimos hacer.

![alt text](imgs/image_4.png)

En el diagrama, hay tres procesos (A, B y C), y cada uno de ellos tiene una peque침a parte de la memoria f칤sica de 512KB asignada para ellos. Suponiendo una sola CPU, el sistema operativo elige ejecutar uno de los procesos (digamos A), mientras los otros (B y C) permanecen en la cola de listos esperando ser ejecutados. A medida que el tiempo compartido se hizo m치s popular, probablemente puedes adivinar que se impusieron nuevas demandas al sistema operativo. En particular, permitir que varios programas residan simult치neamente en la memoria hace que la protecci칩n sea un tema importante

## Espacio de direcciones

Sin embargo, debemos tener en cuenta a esos molestos usuarios, y hacerlo requiere que el sistema operativo (SO) cree una abstracci칩n f치cil de usar de la memoria f칤sica. Llamamos a esta abstracci칩n el espacio de direcciones, y es la vista de la memoria que tiene el programa en ejecuci칩n dentro del sistema. Entender esta abstracci칩n fundamental de la memoria que proporciona el SO es clave para comprender c칩mo se virtualiza la memoria.

El espacio de direcciones de un proceso contiene todo el estado de la memoria del programa en ejecuci칩n. Por ejemplo, el c칩digo del programa (las instrucciones) tiene que residir en alg칰n lugar de la memoria, y por lo tanto est치 en el espacio de direcciones. El programa, mientras se ejecuta, utiliza un stack para hacer un seguimiento de d칩nde se encuentra en la cadena de llamadas a funciones, as칤 como para asignar variables locales, pasar par치metros y devolver valores de y hacia las rutinas. Finalmente, el heap se utiliza para la memoria asignada din치micamente, gestionada por el usuario, como la que podr칤as obtener de una llamada a malloc() en C o new en un lenguaje orientado a objetos como C++ o Java. Por supuesto, tambi칠n hay otras cosas en el espacio de direcciones (por ejemplo, variables inicializadas est치ticamente), pero por ahora asumamos solo estos tres componentes: **c칩digo, pila y mont칩n.**

![alt text](image.png)

Tenemos un peque침o espacio de direcciones (solo 16KB). El c칩digo del programa reside en la parte superior del espacio de direcciones (comenzando en 0 en este ejemplo, y ocupando los primeros 1KB del espacio de direcciones). El c칩digo es est치tico (y por lo tanto f치cil de ubicar en la memoria), por lo que podemos colocarlo en la parte superior del espacio de direcciones y saber que no necesitar치 m치s espacio mientras el programa se ejecuta.

A continuaci칩n, tenemos las dos regiones del espacio de direcciones que pueden crecer (y reducirse) mientras el programa se ejecuta. Estas son el mont칩n (en la parte superior) y la pila (en la parte inferior). Los colocamos de esta manera porque cada uno necesita poder crecer, y al ponerlos en extremos opuestos del espacio de direcciones, permitimos dicho crecimiento: simplemente deben crecer en direcciones opuestas. As칤, el mont칩n comienza justo despu칠s del c칩digo (en 1KB) y crece hacia abajo (por ejemplo, cuando un usuario solicita m치s memoria a trav칠s de malloc()); la pila comienza en 16KB y crece hacia arriba (por ejemplo, cuando un usuario realiza una llamada a procedimiento). Sin embargo, esta colocaci칩n de la pila y el mont칩n es solo una convenci칩n

Por supuesto, cuando describimos el espacio de direcciones, lo que estamos describiendo es la abstracci칩n que el SO proporciona al programa en ejecuci칩n. El programa realmente no est치 en memoria en las direcciones f칤sicas 0 a 16KB; en realidad, est치 cargado en alguna direcci칩n f칤sica arbitraria. Observa los procesos A, B y C en la Figura 13.2; all칤 puedes ver c칩mo cada proceso se carga en memoria en una direcci칩n diferente. Y aqu칤 surge el problema: cuando el SO hace esto, decimos que el SO est치 virtualizando la memoria, porque el programa en ejecuci칩n piensa que est치 cargado en la memoria en una direcci칩n particular (digamos 0) y tiene un espacio de direcciones potencialmente muy grande (digamos 32 bits o 64 bits);

Cuando, por ejemplo, el proceso A, intenta realizar una carga en la direcci칩n 0 (lo que llamaremos una direcci칩n virtual), de alguna manera el SO, junto con el soporte del hardware, tendr치 que asegurarse de que la carga no se realice realmente en la direcci칩n f칤sica 0, sino en la direcci칩n f칤sica 320KB (donde A est치 cargado en la memoria)

## Objetivos

La memoria virtual (VM) tiene tres objetivos principales:

**Transparencia**: El sistema operativo (SO) debe hacer que la VM sea invisible para los programas, d치ndoles la impresi칩n de que tienen su propia memoria f칤sica privada. Detr치s de esto, el SO y el hardware gestionan y comparten la memoria entre m칰ltiples procesos.

**Eficiencia**: La VM debe ser eficiente en t칠rminos de tiempo y espacio. El SO debe evitar ralentizar los programas y no utilizar demasiada memoria adicional. Para esto, depende del soporte de hardware, como las TLBs (Tablas de Traducci칩n de Direcciones).

**Protecci칩n**: La VM debe garantizar que los procesos no puedan acceder ni modificar la memoria de otros procesos ni del propio SO. Esto asegura un entorno aislado y seguro para cada proceso, evitando interferencias o posibles da침os de otros procesos defectuosos o maliciosos.

## El principio de aislaiento

El aislamiento es un principio clave para construir sistemas confiables. Si dos entidades est치n correctamente aisladas una de la otra, esto implica que una puede fallar sin afectar a la otra. Los sistemas operativos se esfuerzan por aislar los procesos entre s칤 y, de esta manera, evitar que uno da침e al otro. Al usar el aislamiento de memoria, el SO garantiza a칰n m치s que los programas en ejecuci칩n no puedan afectar el funcionamiento del propio SO subyacente.

Algunos sistemas operativos modernos llevan el aislamiento a칰n m치s lejos, separando partes del SO de otras partes del mismo SO. Estos microkernels pueden proporcionar una mayor confiabilidad que los dise침os t칤picos de n칰cleos monol칤ticos.

## Resumen

Hemos introducido un subsistema clave del sistema operativo: la memoria virtual (VM). Este sistema es responsable de proporcionar la ilusi칩n de un espacio de direcciones amplio, disperso y privado para cada programa en ejecuci칩n. Cada espacio de direcciones virtual contiene todas las instrucciones y datos del programa, los cuales pueden ser referenciados mediante direcciones virtuales. El SO, con ayuda del hardware, convierte estas referencias de memoria virtual en direcciones f칤sicas, que son utilizadas para acceder o actualizar la informaci칩n en la memoria f칤sica. El SO brinda este servicio a m칰ltiples procesos simult치neamente, asegurando la protecci칩n entre ellos y del propio sistema operativo. Este enfoque requiere una combinaci칩n de mecanismos complejos y pol칤ticas cr칤ticas. 춰Vamos a empezar desde los fundamentos!

## ASIDE: Cada direcci칩n que ves es virtual

Cuando escribes un programa en C y muestras un puntero, el valor que ves (normalmente un n칰mero grande en hexadecimal) es una direcci칩n virtual. Cualquier direcci칩n que puedas imprimir en un programa a nivel de usuario es virtual. Solo el sistema operativo (SO), a trav칠s de su t칠cnica de virtualizaci칩n de la memoria, sabe d칩nde est치n realmente esas instrucciones y datos en la memoria f칤sica.

Por ejemplo, el siguiente programa en C (va.c) imprime las ubicaciones del c칩digo (funci칩n main), de una direcci칩n en el heap obtenida por malloc() y de una variable en la pila:

```C
#include <stdio.h>
#include <stdlib.h>
int main(int argc, char *argv[]) {
    printf("location of code : %p\n", main);
    printf("location of heap : %p\n", malloc(100e6));
    int x = 3;
    printf("location of stack: %p\n", &x);
    return x;
}
```

```yaml
location of code: 0x1095afe50
location of heap: 0x1096008c0
location of stack: 0x7fff691aea64
```
